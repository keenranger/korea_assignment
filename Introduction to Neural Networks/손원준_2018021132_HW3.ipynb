{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> Provided on May 20, Due on June 03 [BRI516, Spring/2020] </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For homework in general:\n",
    "* Install `Anaconda` and create an environment with `NumPy`, `Pandas`, `Matplotlib`, `scikit-learn`,`scipy` in Python 3.5\n",
    "* Please type the equation and/or text using markdown in jupyter-lab or jupyter-notebook\n",
    "* Please upload your jupyter-notebook file for homework to `Blackboard` \n",
    "* Please discuss your results at least one line of text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## [Hw#3] Regression analysis\n",
    "\n",
    "The dataset (X) provided has a very high-dimensional sample (i.e., number of dimension = 60,837) while there is a limited available number of samples (n = 80). \n",
    "\n",
    "The goal is to predict the target scores (y) from the high-dimensional input, X.\n",
    "* Note that, as you know, this problem is very prone to the so-called, curse-of-dimensionality.\n",
    "    * Thus, you would need to put some effort to optimize your model such as using regularizations\n",
    "\n",
    " \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "### Now, please perform the following to solve this regression problem.\n",
    "\n",
    "* Please try out at least a few models that you learned in the class and show only the results from your best performing regression model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Load all the input sample data X and target values y\n",
    " (a) You can use 'loadmat' function after importing 'scipy.io' to load 'dataset.mat' \n",
    " \n",
    " (b) Please standardize X before using\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (a)\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "mat = scipy.io.loadmat('dataset.mat')\n",
    "Y = np.transpose(mat[\"y\"])\n",
    "X = np.transpose(mat[\"X\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Before preprocessing>\n",
      "mean : 0.11365045829970055, std : 0.46106094040209705\n",
      "<After preprocessing>\n",
      "mean : -2.0650195923607992e-18, std : 1.0000000000000002\n"
     ]
    }
   ],
   "source": [
    "# (b)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "sc_x = StandardScaler()\n",
    "X_std = sc_x.fit_transform(X)\n",
    "print(\"<Before preprocessing>\")\n",
    "print(\"mean : {}, std : {}\".format(np.mean(mat[\"X\"]), np.std(mat[\"X\"])))\n",
    "print(\"<After preprocessing>\")\n",
    "print(\"mean : {}, std : {}\".format(np.mean(X_std), np.std(X_std)))\n",
    "\n",
    "# 평균이 0, 표준편차가 1이 되도록 변환되었음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Perform the regression analysis based on the nested k-fold cross-validation (k=5) \n",
    " \n",
    " (a) Please evaluate the performance from the training, validation, and test data by the correlation of true and predicted values \n",
    "\n",
    " (b) Please optimize the potential hyperparameter(s) of your model to get a best performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 445386762245.77, NNZs: 1, Bias: 16765136610.075619, T: 80, Avg. loss: 284891772564828566807642112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 178526456378.09, NNZs: 1, Bias: -11978742752.505222, T: 160, Avg. loss: 339102485419270725879988224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 171849092690.06, NNZs: 1, Bias: -19230823798.235909, T: 240, Avg. loss: 191904308836995724807766016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 13673534825.01, NNZs: 1, Bias: 19112869561.506561, T: 320, Avg. loss: 163926981577044725115912192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 176073261480.92, NNZs: 1, Bias: 44219117336.061546, T: 400, Avg. loss: 122787857408219317773795328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 208102796148.32, NNZs: 1, Bias: 72631771558.075928, T: 480, Avg. loss: 165786837085032378481508352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 63912193563.81, NNZs: 1, Bias: 44668841176.900757, T: 560, Avg. loss: 138064121963915754019487744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 89440266540.29, NNZs: 1, Bias: 53629640996.921417, T: 640, Avg. loss: 136747724103202774674571264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 7265608999.87, NNZs: 1, Bias: 84739225996.645157, T: 720, Avg. loss: 102897410254755876533436416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 36486225290.32, NNZs: 1, Bias: 68737058832.938202, T: 800, Avg. loss: 125506475800297056445136896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 106310645372.28, NNZs: 1, Bias: 74321599756.618469, T: 880, Avg. loss: 96473432601159910148800512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 298244234046.50, NNZs: 1, Bias: 65968467687.573723, T: 960, Avg. loss: 88097772096770399983894528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 166405536974.70, NNZs: 1, Bias: 67738446544.727417, T: 1040, Avg. loss: 91021943394760953566330880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 366259315602.38, NNZs: 1, Bias: 76404438518.048752, T: 1120, Avg. loss: 72023377176292044570624000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 50639069354.38, NNZs: 1, Bias: 58886240005.220459, T: 1200, Avg. loss: 102261969947005350406258688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 8601459029.45, NNZs: 1, Bias: 26563988501.115128, T: 1280, Avg. loss: 97700281061688145052958720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 123891086472.67, NNZs: 1, Bias: 46745985972.008591, T: 1360, Avg. loss: 74583718235436758360653824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 28014545111.22, NNZs: 1, Bias: 49573828598.753105, T: 1440, Avg. loss: 100511250938296200333361152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 255218548869.54, NNZs: 1, Bias: 38063234017.961952, T: 1520, Avg. loss: 84191416830645292337463296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 19 epochs took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn import linear_model\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe_lr = Pipeline([\n",
    "        ('reduce_dim', PCA()),\n",
    "        ('regressor', SGDRegressor(max_iter=100, verbose=1, penalty=\"l1\"))\n",
    "        ])\n",
    "\n",
    "param_grid=[\n",
    "        {\n",
    "            \"reduce_dim__n_components\": range(1,11),\n",
    "            \"regressor__alpha\": [1e-5,1e-4,1e-3,1e-2,1e-1], \n",
    "            \"regressor__l1_ratio\": [0.001,0.25,0.5,0.75,0.999]\n",
    "        } \n",
    "    ]\n",
    "\n",
    "gs = GridSearchCV(estimator=pipe_lr, param_grid=param_grid, scoring=\"r2\",cv=5, n_jobs=-1)\n",
    "gs = gs.fit(X_std, Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 24798214.41, NNZs: 1, Bias: -387181.508429, T: 6, Avg. loss: 180592300693853.218750\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 104501065997.60, NNZs: 1, Bias: -5419087917.746258, T: 12, Avg. loss: 494990567992537979610464256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1289858601889.85, NNZs: 1, Bias: -524903693.649510, T: 18, Avg. loss: 375939148532636782082129920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 47497272148.24, NNZs: 1, Bias: -75493026.168237, T: 24, Avg. loss: 7128424204403546756430692352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 527403161124.62, NNZs: 1, Bias: -13891827396.004040, T: 30, Avg. loss: 1605797137755819698684952576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 650046180575.41, NNZs: 1, Bias: -11191261004.243389, T: 36, Avg. loss: 2341266997250899183992307712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 6 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 439180832147.91, NNZs: 1, Bias: 12390692714.408302, T: 12, Avg. loss: 356532906032513087375933440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 24605916963.49, NNZs: 1, Bias: 11829031701.903419, T: 24, Avg. loss: 1007609673657360902462111744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 315721334840.85, NNZs: 1, Bias: 19910302695.110912, T: 36, Avg. loss: 831212495366817992734146560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 24382896602.84, NNZs: 1, Bias: 1048634952.938386, T: 48, Avg. loss: 1170852378279438166179971072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 102822584256.31, NNZs: 1, Bias: 23068790594.607716, T: 60, Avg. loss: 691847319089776968089993216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 604250381154.74, NNZs: 1, Bias: 1850365417.570154, T: 72, Avg. loss: 375886272376938178923200512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 6 epochs took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 353151080189.60, NNZs: 1, Bias: -13068699276.182453, T: 19, Avg. loss: 310080431983311539486588928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 26035691196.94, NNZs: 1, Bias: -16506534996.481581, T: 38, Avg. loss: 826676303398298926964539392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 56769918801.85, NNZs: 1, Bias: -27608818226.454735, T: 57, Avg. loss: 512053937371257347732668416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 320805086374.53, NNZs: 1, Bias: -37563006709.898705, T: 76, Avg. loss: 333748307912397414790594560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 155552465693.11, NNZs: 1, Bias: -57270076526.084824, T: 95, Avg. loss: 478365967729110013236477952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 33602150809.91, NNZs: 1, Bias: -53048719175.123985, T: 114, Avg. loss: 505237419411435478704979968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 6 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 224710687053.26, NNZs: 1, Bias: 12642633398.847227, T: 25, Avg. loss: 204944272192138990894186496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 145282940071.06, NNZs: 1, Bias: 41802196367.934219, T: 50, Avg. loss: 420685526794085702494584832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 224726047881.85, NNZs: 1, Bias: 17529272976.822098, T: 75, Avg. loss: 297854859882805105256300544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 369986884106.31, NNZs: 1, Bias: 27411911828.986343, T: 100, Avg. loss: 250456531176068542244061184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 405955527408.92, NNZs: 1, Bias: 33230603129.187611, T: 125, Avg. loss: 331899497587289069499449344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 152144996765.51, NNZs: 1, Bias: 29379070218.877048, T: 150, Avg. loss: 277889319105316726027321344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 6 epochs took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 866440366782.81, NNZs: 1, Bias: 48446050475.076675, T: 32, Avg. loss: 113050719962811251139018752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 21887387911.24, NNZs: 1, Bias: 62838667458.723129, T: 64, Avg. loss: 496159752637204058509148160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 277309760498.54, NNZs: 1, Bias: 64052449567.580879, T: 96, Avg. loss: 252184192933812407803838464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 177380888851.49, NNZs: 1, Bias: 74335038667.902298, T: 128, Avg. loss: 144221994884115497310224384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 122112077250.35, NNZs: 1, Bias: 52451685705.513588, T: 160, Avg. loss: 152108711943545132794511360.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 83251255628.99, NNZs: 1, Bias: 54440500614.024666, T: 192, Avg. loss: 199351474293512016293265408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 6 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 108152761177.99, NNZs: 1, Bias: 17344143134.274448, T: 38, Avg. loss: 124007824186127175785644032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 266546042377.80, NNZs: 1, Bias: -6678335921.947371, T: 76, Avg. loss: 276581295555563048944009216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 342244793768.09, NNZs: 1, Bias: -8145898654.596748, T: 114, Avg. loss: 200170454345785727606849536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 157959916528.03, NNZs: 1, Bias: -4129415050.478758, T: 152, Avg. loss: 168335252542755220102316032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 97889845237.36, NNZs: 1, Bias: 4264749536.639952, T: 190, Avg. loss: 150033235493428723573587968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 600671536609.64, NNZs: 1, Bias: -12063099198.220819, T: 228, Avg. loss: 61795741377279465390866432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 332015511160.51, NNZs: 1, Bias: -16951961014.454252, T: 266, Avg. loss: 151347856066917452604243968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 10702897546.76, NNZs: 1, Bias: -20917789018.069550, T: 304, Avg. loss: 107258451364292406345203712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 127552002934.24, NNZs: 1, Bias: -16144513720.620935, T: 342, Avg. loss: 155054851946741552818159616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 109438043718.32, NNZs: 1, Bias: -14671501175.832121, T: 380, Avg. loss: 67295618302300728661639168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 60690078544.76, NNZs: 1, Bias: -10466273900.857662, T: 418, Avg. loss: 84806086558817945852575744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 11 epochs took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 680045851067.24, NNZs: 1, Bias: -17567987060.094231, T: 44, Avg. loss: 1185623630323629990652936192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 100314898445.15, NNZs: 1, Bias: -15411491951.528584, T: 88, Avg. loss: 644675443186120631032741888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 20459927006.11, NNZs: 1, Bias: 3039487691.192685, T: 132, Avg. loss: 454103867735025619111510016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 147385333483.76, NNZs: 1, Bias: 5474852465.456364, T: 176, Avg. loss: 325579586058528442428686336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 56877755764.70, NNZs: 1, Bias: 23137633477.127522, T: 220, Avg. loss: 238622081812505117363011584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 243981854387.66, NNZs: 1, Bias: 54595976068.821793, T: 264, Avg. loss: 238008488466437392306274304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 27901292402.56, NNZs: 1, Bias: 74197641600.302414, T: 308, Avg. loss: 212688027251100374053945344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 59449772902.66, NNZs: 1, Bias: 82455209438.212280, T: 352, Avg. loss: 247376004643252115416809472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 98730024796.93, NNZs: 1, Bias: 85028827603.178207, T: 396, Avg. loss: 177603356513631992950030336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 2481907237.66, NNZs: 1, Bias: 72169090019.037399, T: 440, Avg. loss: 227672637824235845080580096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 65377754646.47, NNZs: 1, Bias: 55822690067.624519, T: 484, Avg. loss: 112166223727985138602082304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 323026723022.45, NNZs: 1, Bias: 48902006051.454689, T: 528, Avg. loss: 118128157093093119010799616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 382638632325.25, NNZs: 1, Bias: 52325239992.009758, T: 572, Avg. loss: 151698972689486224637820928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 68688610404.75, NNZs: 1, Bias: 61411185587.988861, T: 616, Avg. loss: 223593167602689696105234432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 44872290177.63, NNZs: 1, Bias: 72687988596.077042, T: 660, Avg. loss: 220147928839599637514944512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 51009606869.98, NNZs: 1, Bias: 51431926808.544174, T: 704, Avg. loss: 164642627290953323489787904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 16 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 230149146250.68, NNZs: 1, Bias: -40997235391.720314, T: 51, Avg. loss: 500386894890120381313581056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 24459261872.38, NNZs: 1, Bias: -59707570360.613075, T: 102, Avg. loss: 522273230567679343397437440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 191045271296.40, NNZs: 1, Bias: -77728134063.324203, T: 153, Avg. loss: 247765713749092814622294016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 182468383528.73, NNZs: 1, Bias: -83848635722.231476, T: 204, Avg. loss: 305383807029064071364214784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 56856444350.62, NNZs: 1, Bias: -85930113550.489700, T: 255, Avg. loss: 221004987302179391250890752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 79480099032.51, NNZs: 1, Bias: -64003698757.152161, T: 306, Avg. loss: 206504296113739326539431936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 76234596367.94, NNZs: 1, Bias: -43054375807.932007, T: 357, Avg. loss: 247797512822536079354626048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 332790874659.10, NNZs: 1, Bias: -63897222911.352715, T: 408, Avg. loss: 146449272952190164424196096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 107297973424.03, NNZs: 1, Bias: -47590394859.366783, T: 459, Avg. loss: 186789994543172152750768128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 116535659770.36, NNZs: 1, Bias: -50152179589.607422, T: 510, Avg. loss: 216959472411235931203305472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 71735325861.78, NNZs: 1, Bias: -51984357051.157028, T: 561, Avg. loss: 163300207897220305584652288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 3036203004.09, NNZs: 1, Bias: -18979989523.310719, T: 612, Avg. loss: 163319233606445425349361664.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 178312290579.86, NNZs: 1, Bias: -19561123904.817356, T: 663, Avg. loss: 117068037468129733180915712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 48614978923.06, NNZs: 1, Bias: -15554737936.663353, T: 714, Avg. loss: 118373497082140624378920960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 117817545233.82, NNZs: 1, Bias: -14679936220.507351, T: 765, Avg. loss: 122711088255734200156553216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 210681601409.30, NNZs: 1, Bias: -7916238141.830849, T: 816, Avg. loss: 108479492236412329400467456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 30371106616.12, NNZs: 1, Bias: -23184056029.749332, T: 867, Avg. loss: 105217633558457393388453888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 107978837566.14, NNZs: 1, Bias: -13762964507.299404, T: 918, Avg. loss: 102010211562612696220172288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 210333023124.85, NNZs: 1, Bias: 6239567470.569071, T: 969, Avg. loss: 90303245601095635464880128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 26141424259.72, NNZs: 1, Bias: 6323465160.859611, T: 1020, Avg. loss: 105749505399583293455728640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 33384602895.30, NNZs: 1, Bias: -17850549910.330193, T: 1071, Avg. loss: 117178591536025547275501568.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 141683809711.53, NNZs: 1, Bias: -13720701097.735840, T: 1122, Avg. loss: 118759093476371955126894592.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 148825167518.06, NNZs: 1, Bias: -18239021532.282707, T: 1173, Avg. loss: 103443677005225095323451392.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 12615868518.66, NNZs: 1, Bias: -17978568640.507454, T: 1224, Avg. loss: 86819250279809333506080768.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 151625918521.18, NNZs: 1, Bias: -12457674663.342571, T: 1275, Avg. loss: 100697855170268128358694912.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 280842266505.73, NNZs: 1, Bias: -20862980951.709736, T: 1326, Avg. loss: 97956840283269110737928192.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 132606972538.84, NNZs: 1, Bias: -19148942890.508610, T: 1377, Avg. loss: 118467061907142841989070848.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 135499964283.34, NNZs: 1, Bias: 8473181214.041523, T: 1428, Avg. loss: 78154331777419023333982208.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 27948653379.19, NNZs: 1, Bias: 12196987373.393579, T: 1479, Avg. loss: 133767739711154075520204800.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 124592787493.92, NNZs: 1, Bias: 22069664900.040047, T: 1530, Avg. loss: 107322810684211861257191424.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 120421172012.31, NNZs: 1, Bias: 45245420553.104134, T: 1581, Avg. loss: 82272341301840628957577216.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 8700898019.78, NNZs: 1, Bias: 47350608509.612488, T: 1632, Avg. loss: 102232598251071741100032000.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 45810812540.91, NNZs: 1, Bias: 61326301747.451004, T: 1683, Avg. loss: 124351787181945046045818880.000000\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 33 epochs took 0.01 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 565413971962.98, NNZs: 1, Bias: -12212351524.271542, T: 57, Avg. loss: 427624269285993552535355392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 117026238974.13, NNZs: 1, Bias: 1309100676.044951, T: 114, Avg. loss: 366228653921288590718926848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 93273300382.53, NNZs: 1, Bias: 8106452702.237570, T: 171, Avg. loss: 220802702274095918734114816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 29945481770.89, NNZs: 1, Bias: -29298228232.927258, T: 228, Avg. loss: 206508002498261678727102464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 420993285675.30, NNZs: 1, Bias: -29153196720.837688, T: 285, Avg. loss: 134125520847077794037891072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 76083723602.81, NNZs: 1, Bias: -28299062200.897900, T: 342, Avg. loss: 160108864307812972497993728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 451537604217.02, NNZs: 1, Bias: -8825324208.067640, T: 399, Avg. loss: 117670793507080998425198592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 73408165643.75, NNZs: 1, Bias: -8744888172.667601, T: 456, Avg. loss: 264537883000127026282627072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 11992295612.98, NNZs: 1, Bias: -2122463424.638723, T: 513, Avg. loss: 121319694751918252502286336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 35262611885.09, NNZs: 1, Bias: -9137634554.206083, T: 570, Avg. loss: 132340135721107382616457216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 5285669042.25, NNZs: 1, Bias: -3779347604.816245, T: 627, Avg. loss: 120687286456552184975720448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 288434370172.49, NNZs: 1, Bias: 18278846469.441685, T: 684, Avg. loss: 93508096233442622138482688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 12552382057.41, NNZs: 1, Bias: 6307283384.697724, T: 741, Avg. loss: 89290011201703933405822976.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 43165999336.70, NNZs: 1, Bias: 13871551164.149231, T: 798, Avg. loss: 105145822948724269801013248.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 13772349287.55, NNZs: 1, Bias: 20305343265.430054, T: 855, Avg. loss: 93297539610409787843411968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 312137834096.89, NNZs: 1, Bias: -7303841531.075718, T: 912, Avg. loss: 105161906391550133255798784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 119415319579.18, NNZs: 1, Bias: -14241231585.761223, T: 969, Avg. loss: 116305927725669710057963520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 310407985369.79, NNZs: 1, Bias: -15708515663.429459, T: 1026, Avg. loss: 87567993088312094964580352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 257116670826.15, NNZs: 1, Bias: -25957709432.137493, T: 1083, Avg. loss: 109898284797361270449766400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 6259205768.74, NNZs: 1, Bias: -10563761478.498709, T: 1140, Avg. loss: 84353201861557695400640512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 9292119506.67, NNZs: 1, Bias: -23046424200.196396, T: 1197, Avg. loss: 65229423598966932361969664.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 96963904313.87, NNZs: 1, Bias: -20460051320.926571, T: 1254, Avg. loss: 77617088127969269873901568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 156213377905.92, NNZs: 1, Bias: -21876510459.358681, T: 1311, Avg. loss: 70504111637415856328146944.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 94439703035.38, NNZs: 1, Bias: -24683043119.571529, T: 1368, Avg. loss: 67261629245827506671452160.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 1360242586.16, NNZs: 1, Bias: -36559648346.065468, T: 1425, Avg. loss: 105347261337801903174582272.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 107326971158.34, NNZs: 1, Bias: -30793761439.783215, T: 1482, Avg. loss: 80032289074429145661833216.000000\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 26 epochs took 0.01 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 8276569149.11, NNZs: 1, Bias: -11684208817.050758, T: 64, Avg. loss: 595674820686751296944865280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 290006930092.68, NNZs: 1, Bias: -22366138969.314667, T: 128, Avg. loss: 382857227028027470761689088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 57078464062.48, NNZs: 1, Bias: -40421978237.847481, T: 192, Avg. loss: 258357540139873096960049152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 247918444499.26, NNZs: 1, Bias: -32462944477.391487, T: 256, Avg. loss: 225420048042945020935798784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 256393331271.03, NNZs: 1, Bias: -67371536782.836815, T: 320, Avg. loss: 167066338723198849286930432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 386397243730.94, NNZs: 1, Bias: -72112055095.549194, T: 384, Avg. loss: 204229847644257209345376256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 45687523143.89, NNZs: 1, Bias: -102246773753.908264, T: 448, Avg. loss: 207049886105537026786852864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 418734419480.79, NNZs: 1, Bias: -121982296722.801712, T: 512, Avg. loss: 103448375767723773909794816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 355068599472.94, NNZs: 1, Bias: -113473322431.337601, T: 576, Avg. loss: 141650044001038807827742720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 44545442499.73, NNZs: 1, Bias: -110366930899.455292, T: 640, Avg. loss: 134209881446321885659791360.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 139433742294.04, NNZs: 1, Bias: -139958613381.936249, T: 704, Avg. loss: 108476147651529844333740032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 13762249836.19, NNZs: 1, Bias: -146716811831.283142, T: 768, Avg. loss: 101764004859876506488274944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 166431232661.05, NNZs: 1, Bias: -161948108550.383698, T: 832, Avg. loss: 137412341906707971382968320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 139329983613.86, NNZs: 1, Bias: -151252876014.997040, T: 896, Avg. loss: 107946074455362202276724736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 155553597568.55, NNZs: 1, Bias: -154258637649.135773, T: 960, Avg. loss: 87544319396974926376206336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 109338582641.12, NNZs: 1, Bias: -146958918998.509644, T: 1024, Avg. loss: 92410357529115829548875776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 200938768996.27, NNZs: 1, Bias: -162176925287.581909, T: 1088, Avg. loss: 97395276669039232036110336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 109599145784.45, NNZs: 1, Bias: -154179595570.902344, T: 1152, Avg. loss: 100185800090214912447479808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 242050192571.74, NNZs: 1, Bias: -154524807524.392059, T: 1216, Avg. loss: 75189779569977834640244736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 26854990985.34, NNZs: 1, Bias: -149575232241.816925, T: 1280, Avg. loss: 101782686361137681692360704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 8372267069.97, NNZs: 1, Bias: -131118204287.044678, T: 1344, Avg. loss: 70248852767230921189359616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 4833125449.17, NNZs: 1, Bias: -137940067762.127625, T: 1408, Avg. loss: 82116962006517056802914304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 91753242666.26, NNZs: 1, Bias: -125127668068.688400, T: 1472, Avg. loss: 81556075595916191817793536.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 60999940947.98, NNZs: 1, Bias: -102576463198.993698, T: 1536, Avg. loss: 83876537306918933678260224.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 29418781723.58, NNZs: 1, Bias: -115392431764.110565, T: 1600, Avg. loss: 80651261057534483815727104.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 269735733364.61, NNZs: 1, Bias: -100029154184.387436, T: 1664, Avg. loss: 69333003193239804483469312.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 137287490121.61, NNZs: 1, Bias: -97440744524.070816, T: 1728, Avg. loss: 71713734603322789292146688.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 123484878639.39, NNZs: 1, Bias: -93452871325.069656, T: 1792, Avg. loss: 63138757670796562427543552.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 50307358269.31, NNZs: 1, Bias: -82282683573.128632, T: 1856, Avg. loss: 65705566365252892007333888.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 20316538970.46, NNZs: 1, Bias: -59547984276.243019, T: 1920, Avg. loss: 114684981116806338743107584.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 1718956265.36, NNZs: 1, Bias: -66450939460.748337, T: 1984, Avg. loss: 74057288623621136371941376.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 131016361694.39, NNZs: 1, Bias: -65982698587.383995, T: 2048, Avg. loss: 60052784516079921978671104.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 166417779232.34, NNZs: 1, Bias: -63694300153.795990, T: 2112, Avg. loss: 65376299051957330202591232.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 12354496036.04, NNZs: 1, Bias: -60492094682.193787, T: 2176, Avg. loss: 69097988647561050651099136.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 325232722950.77, NNZs: 1, Bias: -68657587781.494186, T: 2240, Avg. loss: 43900397538523652802215936.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 192712565734.14, NNZs: 1, Bias: -71113422124.034149, T: 2304, Avg. loss: 76255181233760080903536640.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 203547997579.35, NNZs: 1, Bias: -67484441715.415421, T: 2368, Avg. loss: 56922298048758814355750912.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 102311932957.09, NNZs: 1, Bias: -55427354211.452484, T: 2432, Avg. loss: 70913654295927195378384896.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 52098488198.96, NNZs: 1, Bias: -59010659584.422554, T: 2496, Avg. loss: 53386178246123090599739392.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 202215221946.29, NNZs: 1, Bias: -40140005164.339119, T: 2560, Avg. loss: 66406659598603471328116736.000000\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 40 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 649571.77, NNZs: 1, Bias: 2252.565598, T: 6, Avg. loss: 10218808564.246971\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1516656906631.88, NNZs: 1, Bias: 5864531307.694926, T: 12, Avg. loss: 14984923134660777321955328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1268353116292.88, NNZs: 1, Bias: 25999047566.327511, T: 18, Avg. loss: 3094049146355860456282783744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1048786380031.66, NNZs: 1, Bias: 44433169735.486954, T: 24, Avg. loss: 2622284894882875691308679168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 934527106382.70, NNZs: 1, Bias: 44541547760.585670, T: 30, Avg. loss: 1786270293127579475466256384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 850520997627.36, NNZs: 1, Bias: 44323920866.756699, T: 36, Avg. loss: 1773842899349171670949560320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 6 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 769189576609.66, NNZs: 1, Bias: 11051501488.901516, T: 12, Avg. loss: 37014754096278484593672192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 277063881537.62, NNZs: 1, Bias: -10345718865.576345, T: 24, Avg. loss: 2840473501870722632560672768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 587578149137.41, NNZs: 1, Bias: -11935535557.425131, T: 36, Avg. loss: 2062242702191796917398142976.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 109115701027.61, NNZs: 1, Bias: 15691368130.541063, T: 48, Avg. loss: 1795840819662823598663401472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 153593625507.90, NNZs: 1, Bias: 35260859946.252800, T: 60, Avg. loss: 1476948438447786070145761280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 358230915261.02, NNZs: 1, Bias: 33828529773.322403, T: 72, Avg. loss: 976432211694664503791714304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 6 epochs took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 733953786546.31, NNZs: 1, Bias: 25249120497.101822, T: 19, Avg. loss: 2562754762476138909610803200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 195272105890.38, NNZs: 1, Bias: 42972769467.189804, T: 38, Avg. loss: 1179615989097149360005709824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 803904944176.56, NNZs: 1, Bias: 33726966810.435436, T: 57, Avg. loss: 628770139006713882331840512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 155737004040.41, NNZs: 1, Bias: 63029510900.813484, T: 76, Avg. loss: 1037559072991072785788829696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 5688786688.66, NNZs: 1, Bias: 41506008309.799095, T: 95, Avg. loss: 1153413503470096779789205504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 13609531938.89, NNZs: 1, Bias: 34668565969.404701, T: 114, Avg. loss: 1097548337587423747290169344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 217210870811.39, NNZs: 1, Bias: 34265111660.950203, T: 133, Avg. loss: 609885786387846891697078272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 132077792043.61, NNZs: 1, Bias: 43102967105.642624, T: 152, Avg. loss: 610021699832214102101458944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 360736339457.63, NNZs: 1, Bias: 45655930102.344772, T: 171, Avg. loss: 566718502440165417209036800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 57383930529.17, NNZs: 1, Bias: 46306170843.019676, T: 190, Avg. loss: 827136085255861389683064832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 29728531086.79, NNZs: 1, Bias: 51269846758.112694, T: 209, Avg. loss: 526393587826462258532188160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 155457665674.33, NNZs: 1, Bias: 45788584994.347229, T: 228, Avg. loss: 711367940326543069517185024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 179082785286.06, NNZs: 1, Bias: 43991132785.125946, T: 247, Avg. loss: 384248037438004371067502592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 190656481481.66, NNZs: 1, Bias: 38196962449.315414, T: 266, Avg. loss: 712570338610316173559988224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 39186020078.36, NNZs: 1, Bias: 47378559064.560959, T: 285, Avg. loss: 580806452784795737781174272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 175558027320.04, NNZs: 1, Bias: 42062305304.100555, T: 304, Avg. loss: 432875131376037794494283776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 97265237333.93, NNZs: 1, Bias: 41510332268.715385, T: 323, Avg. loss: 518563141562181671517683712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 129715337115.15, NNZs: 1, Bias: 41789450253.460785, T: 342, Avg. loss: 386001655573263252608516096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 18 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 130863305794.71, NNZs: 1, Bias: -2486387588.120569, T: 25, Avg. loss: 574306398019865695462883328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 79795262099.57, NNZs: 1, Bias: 3097463513.232542, T: 50, Avg. loss: 871282540726721887816646656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 206246246200.02, NNZs: 1, Bias: 10735036539.342756, T: 75, Avg. loss: 1047322013674115531148361728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 128075434966.46, NNZs: 1, Bias: 24613804956.803829, T: 100, Avg. loss: 661736398938905006554742784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 204574493863.08, NNZs: 1, Bias: 25457011344.300415, T: 125, Avg. loss: 590515567683532089439813632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 138283693284.33, NNZs: 1, Bias: 28398571064.107536, T: 150, Avg. loss: 694783267135899611579809792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 6 epochs took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 478898634928.11, NNZs: 1, Bias: -5180391748.376138, T: 32, Avg. loss: 680812650397616008515813376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 594801222909.56, NNZs: 1, Bias: -26651330702.048531, T: 64, Avg. loss: 436306236630615030191095808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 74188076747.83, NNZs: 1, Bias: -34318301074.565331, T: 96, Avg. loss: 389162453869938806567731200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 7916417750.56, NNZs: 1, Bias: -37363008309.556984, T: 128, Avg. loss: 899620421798639591619559424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 78046437705.84, NNZs: 1, Bias: -44858727206.063065, T: 160, Avg. loss: 446612108002089272568971264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 31399668707.11, NNZs: 1, Bias: -32678124458.845325, T: 192, Avg. loss: 345183562296432365290913792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 26284051749.40, NNZs: 1, Bias: -37691689772.810265, T: 224, Avg. loss: 671206755774823332348690432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 85447887202.12, NNZs: 1, Bias: -58489903197.353264, T: 256, Avg. loss: 336783436543495605625815040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 424450046811.27, NNZs: 1, Bias: -70219800492.977890, T: 288, Avg. loss: 225049775153552288368295936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 41585621924.47, NNZs: 1, Bias: -56954071713.936821, T: 320, Avg. loss: 267882470486819196012331008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 82447925700.78, NNZs: 1, Bias: -35867355324.499741, T: 352, Avg. loss: 391612986989314261020311552.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 287349896507.48, NNZs: 1, Bias: -40948849984.382759, T: 384, Avg. loss: 214440209351827507896123392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 142707894907.44, NNZs: 1, Bias: -38881308961.155899, T: 416, Avg. loss: 317425376481366135619452928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 79465071368.18, NNZs: 1, Bias: -36097447329.254524, T: 448, Avg. loss: 195564141039248530835767296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 73937474154.86, NNZs: 1, Bias: -57771498373.164543, T: 480, Avg. loss: 297433317054909938778767360.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 70556575414.65, NNZs: 1, Bias: -52989414152.771965, T: 512, Avg. loss: 241361507559693818393526272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 536174940145.71, NNZs: 1, Bias: -51380160019.234680, T: 544, Avg. loss: 142823936622971717521768448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 44959946938.33, NNZs: 1, Bias: -64524821286.387245, T: 576, Avg. loss: 288292926296503898184089600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 219568305184.87, NNZs: 1, Bias: -60256385191.687714, T: 608, Avg. loss: 169309387467448284486828032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 95266147589.02, NNZs: 1, Bias: -62349885953.236183, T: 640, Avg. loss: 193028050899836702291918848.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 175943600292.29, NNZs: 1, Bias: -55046391417.159531, T: 672, Avg. loss: 442886909691472615623884800.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 282925619626.99, NNZs: 1, Bias: -53612892364.238884, T: 704, Avg. loss: 146801977140338686796234752.000000\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 22 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 423684099415.96, NNZs: 1, Bias: 27941091424.636295, T: 38, Avg. loss: 1602109192184526334186225664.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 226542269944.14, NNZs: 1, Bias: -15814419728.818335, T: 76, Avg. loss: 955530955266795740761948160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 223819583209.88, NNZs: 1, Bias: 11795919428.443438, T: 114, Avg. loss: 536132143132457708864667648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 355519213419.38, NNZs: 1, Bias: 10169460697.222706, T: 152, Avg. loss: 347116920269182352240934912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 56520678144.07, NNZs: 1, Bias: 6583874507.580341, T: 190, Avg. loss: 347367526910518475374985216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 53327358983.63, NNZs: 1, Bias: -2161516849.117615, T: 228, Avg. loss: 254771273479491485809246208.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 160022031286.71, NNZs: 1, Bias: 28118301388.379623, T: 266, Avg. loss: 223983511717110089810706432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 372063749845.34, NNZs: 1, Bias: 35993576800.989464, T: 304, Avg. loss: 226881197768394718599708672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 239708855895.70, NNZs: 1, Bias: 68219620427.721031, T: 342, Avg. loss: 176672556838575912114978816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 75681688401.05, NNZs: 1, Bias: 62928610246.829666, T: 380, Avg. loss: 246517935738664986806845440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 140193655155.11, NNZs: 1, Bias: 62171253631.576324, T: 418, Avg. loss: 303194399268789231766470656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 10306783044.91, NNZs: 1, Bias: 60149417289.426170, T: 456, Avg. loss: 360638884957756295521239040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 223390304028.19, NNZs: 1, Bias: 69604290026.765747, T: 494, Avg. loss: 214484180668354295530258432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 17381833646.57, NNZs: 1, Bias: 77133065406.657928, T: 532, Avg. loss: 196279070649779156913487872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 14 epochs took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 961256539749.16, NNZs: 1, Bias: -14843931165.249613, T: 44, Avg. loss: 419055472581996939516575744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 366466812167.65, NNZs: 1, Bias: -3960954961.942619, T: 88, Avg. loss: 1247317691821697248503267328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 170520742139.59, NNZs: 1, Bias: -4373650707.360980, T: 132, Avg. loss: 378395148538007828486422528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 29375782888.37, NNZs: 1, Bias: 5276859238.483467, T: 176, Avg. loss: 370436127577106707245957120.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 189946395839.47, NNZs: 1, Bias: 26978092406.852081, T: 220, Avg. loss: 326368957524985999616114688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 165631019707.67, NNZs: 1, Bias: -1624140276.237784, T: 264, Avg. loss: 215663828202770151197638656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 32623415314.67, NNZs: 1, Bias: -12321993532.824837, T: 308, Avg. loss: 265858359723593964330156032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 444414181738.49, NNZs: 1, Bias: -29600242194.579834, T: 352, Avg. loss: 194618025368928023677501440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 121812199944.36, NNZs: 1, Bias: -32917277493.600346, T: 396, Avg. loss: 216734132944511934025170944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 593545135612.78, NNZs: 1, Bias: -44608803661.574448, T: 440, Avg. loss: 170055709869639144080146432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 132917765440.06, NNZs: 1, Bias: -24346122496.444756, T: 484, Avg. loss: 501018932196276006203424768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 208917053232.53, NNZs: 1, Bias: -13969417357.863155, T: 528, Avg. loss: 193923308459556838750289920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 22290854133.06, NNZs: 1, Bias: -7551494227.751427, T: 572, Avg. loss: 165913048673902500165713920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 352355823539.34, NNZs: 1, Bias: -16032173421.544668, T: 616, Avg. loss: 148387938991589648263806976.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 65908832560.87, NNZs: 1, Bias: -10426596461.572441, T: 660, Avg. loss: 198287828143937992710422528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 8107741128.56, NNZs: 1, Bias: -25729327276.855095, T: 704, Avg. loss: 187910057427827042860138496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 146989947974.76, NNZs: 1, Bias: -23382910932.107887, T: 748, Avg. loss: 136745748182497045208104960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 272225414672.25, NNZs: 1, Bias: -1983338747.207341, T: 792, Avg. loss: 122462317409255748009984000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 364554868207.11, NNZs: 1, Bias: 2807310041.460695, T: 836, Avg. loss: 119462140236097542776946688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 233868868112.93, NNZs: 1, Bias: -4867651333.193336, T: 880, Avg. loss: 234285727815128381084663808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 112096731725.91, NNZs: 1, Bias: -15469987516.723715, T: 924, Avg. loss: 135878338746817552993746944.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 2085221261.31, NNZs: 1, Bias: 3310846259.756741, T: 968, Avg. loss: 176437296691367185234264064.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 31687822294.93, NNZs: 1, Bias: 2363160257.638880, T: 1012, Avg. loss: 154323851312107129348816896.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 216519891078.01, NNZs: 1, Bias: -3245192814.454035, T: 1056, Avg. loss: 127548760969041944353177600.000000\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 24 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 350358745441.06, NNZs: 1, Bias: -4010785923.340242, T: 51, Avg. loss: 672979252324075203542908928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 236592370157.16, NNZs: 1, Bias: -17598068594.523369, T: 102, Avg. loss: 502652647712084237003784192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 205376040468.03, NNZs: 1, Bias: 28180888235.074589, T: 153, Avg. loss: 290331042065798311884881920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 48396715055.10, NNZs: 1, Bias: 24560085107.653912, T: 204, Avg. loss: 238204726587818751255642112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 513155710060.66, NNZs: 1, Bias: 32216129288.881439, T: 255, Avg. loss: 251718416750347746325561344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 33353522548.94, NNZs: 1, Bias: 19124712226.837502, T: 306, Avg. loss: 232354397448500060044132352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 70350674650.67, NNZs: 1, Bias: 27116543340.593716, T: 357, Avg. loss: 199520233787355604967227392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 91717046246.12, NNZs: 1, Bias: 54630010528.979980, T: 408, Avg. loss: 213985430545913434330890240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 57602556165.61, NNZs: 1, Bias: 38361652015.184784, T: 459, Avg. loss: 185164131316739808037961728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 241974264200.99, NNZs: 1, Bias: 39077157229.194565, T: 510, Avg. loss: 149539149968175707453390848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 65312730698.59, NNZs: 1, Bias: 43338495101.021713, T: 561, Avg. loss: 187514098721241747609878528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 159908338629.24, NNZs: 1, Bias: 32494661163.398136, T: 612, Avg. loss: 125079801669601421401522176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 518453381660.11, NNZs: 1, Bias: 33823201396.980640, T: 663, Avg. loss: 142701128734497348400447488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 216678146141.08, NNZs: 1, Bias: 35579834380.803764, T: 714, Avg. loss: 150788680201176516244013056.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 62147805850.86, NNZs: 1, Bias: 29728599013.303501, T: 765, Avg. loss: 143896608616445705229172736.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 62257429278.33, NNZs: 1, Bias: 21393864180.479507, T: 816, Avg. loss: 114530516382047279553445888.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 202379478396.96, NNZs: 1, Bias: 1301675504.509581, T: 867, Avg. loss: 186451064525731209827844096.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 6284696168.56, NNZs: 1, Bias: 7817355897.784664, T: 918, Avg. loss: 105165025674070004988903424.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 7295173927.32, NNZs: 1, Bias: 7630582916.369695, T: 969, Avg. loss: 63847440913855164257927168.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 117913218557.93, NNZs: 1, Bias: 7655276196.494546, T: 1020, Avg. loss: 87797171847079337513713664.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 234845325644.76, NNZs: 1, Bias: 1495778753.766171, T: 1071, Avg. loss: 132235407026358482716590080.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 26278666291.60, NNZs: 1, Bias: -10437448550.731943, T: 1122, Avg. loss: 131336071246359165155672064.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 25223167666.40, NNZs: 1, Bias: -10433275226.906441, T: 1173, Avg. loss: 172002114356201925340299264.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 902415081.72, NNZs: 1, Bias: -20304584843.316006, T: 1224, Avg. loss: 107949363085810341632802816.000000\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 24 epochs took 0.01 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 71405423405.92, NNZs: 1, Bias: 18754191702.927868, T: 57, Avg. loss: 543537668601821532291858432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 309914047251.37, NNZs: 1, Bias: -11730156758.594454, T: 114, Avg. loss: 505298988387174732737282048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 114336986408.33, NNZs: 1, Bias: -49085171334.666695, T: 171, Avg. loss: 340549229694129365762179072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 12522133874.38, NNZs: 1, Bias: -51899769988.006638, T: 228, Avg. loss: 176165425328011565533757440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 162635084211.06, NNZs: 1, Bias: -77926917565.462952, T: 285, Avg. loss: 177247794363210698495885312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 63889951605.75, NNZs: 1, Bias: -125391725092.931305, T: 342, Avg. loss: 167337672707587454648975360.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 83209103080.53, NNZs: 1, Bias: -121698656539.854828, T: 399, Avg. loss: 319386358476265275380465664.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 36406977022.46, NNZs: 1, Bias: -104605750987.546143, T: 456, Avg. loss: 156889180529238540770344960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 157662898311.81, NNZs: 1, Bias: -112479867267.561691, T: 513, Avg. loss: 133137433108266475130454016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 21336162133.23, NNZs: 1, Bias: -103807517951.116150, T: 570, Avg. loss: 177259986780794889716105216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 72147825595.04, NNZs: 1, Bias: -103343847009.367783, T: 627, Avg. loss: 115066451273387009485307904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 93357802861.51, NNZs: 1, Bias: -126678826702.330200, T: 684, Avg. loss: 150010233737287424551157760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 42824887201.99, NNZs: 1, Bias: -134904805643.520218, T: 741, Avg. loss: 111894293535872972738265088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 87914473622.54, NNZs: 1, Bias: -108700476998.941040, T: 798, Avg. loss: 160222879756578076672131072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 2833907365.23, NNZs: 1, Bias: -118886931084.622421, T: 855, Avg. loss: 110833462946498999759142912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 93020251915.62, NNZs: 1, Bias: -109729450874.572144, T: 912, Avg. loss: 115704943315754480184590336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 190955468131.25, NNZs: 1, Bias: -122535335108.311874, T: 969, Avg. loss: 89809190415543378414403584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 16995410781.20, NNZs: 1, Bias: -112333583751.165680, T: 1026, Avg. loss: 96625213847799867469987840.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 106065724445.16, NNZs: 1, Bias: -113207169100.816315, T: 1083, Avg. loss: 156602997915430985033318400.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 195549935565.99, NNZs: 1, Bias: -91523292023.156342, T: 1140, Avg. loss: 105800277779852884870955008.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 4054505085.48, NNZs: 1, Bias: -106291466204.703445, T: 1197, Avg. loss: 92489743773478757953699840.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 122445025018.73, NNZs: 1, Bias: -105768450477.521103, T: 1254, Avg. loss: 81264127671641653267922944.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 100351447584.11, NNZs: 1, Bias: -110203810689.605042, T: 1311, Avg. loss: 79577516520589529117097984.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 42472675378.34, NNZs: 1, Bias: -111893404184.770004, T: 1368, Avg. loss: 100020803493363896851365888.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 52049977430.36, NNZs: 1, Bias: -107762300720.246445, T: 1425, Avg. loss: 71120175188164443809775616.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 2620493784.51, NNZs: 1, Bias: -93200238641.908798, T: 1482, Avg. loss: 116819383088363542126002176.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 50625950357.81, NNZs: 1, Bias: -99340432076.391586, T: 1539, Avg. loss: 76293684561365742515126272.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 16019989409.86, NNZs: 1, Bias: -84737319272.789551, T: 1596, Avg. loss: 84052493107345065070559232.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 138052476396.83, NNZs: 1, Bias: -97272385275.624252, T: 1653, Avg. loss: 76248108659276328529297408.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 94856606930.65, NNZs: 1, Bias: -105885521018.451538, T: 1710, Avg. loss: 60740804941768109162758144.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 45302092401.22, NNZs: 1, Bias: -101192749723.161255, T: 1767, Avg. loss: 133889831197085968451502080.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 39008848290.02, NNZs: 1, Bias: -97299761300.279175, T: 1824, Avg. loss: 77859376020757949349625856.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 26540455972.38, NNZs: 1, Bias: -100264471665.718369, T: 1881, Avg. loss: 70822806257732277766193152.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 29366093563.69, NNZs: 1, Bias: -113046089304.011108, T: 1938, Avg. loss: 75637487715163119556755456.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 37439000357.92, NNZs: 1, Bias: -102859947450.414368, T: 1995, Avg. loss: 60083455280122674370576384.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 28864477116.67, NNZs: 1, Bias: -87281364863.654846, T: 2052, Avg. loss: 79680880128343211591598080.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 24294475312.93, NNZs: 1, Bias: -87773186410.407898, T: 2109, Avg. loss: 68146891007843377667375104.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 43017274875.15, NNZs: 1, Bias: -77977289657.930679, T: 2166, Avg. loss: 88111207520946001234886656.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 131452610041.87, NNZs: 1, Bias: -66312202697.753555, T: 2223, Avg. loss: 67420268203944135689764864.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 14348242197.13, NNZs: 1, Bias: -60837139694.082100, T: 2280, Avg. loss: 69557028004907712730103808.000000\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 40 epochs took 0.01 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 163258176176.40, NNZs: 1, Bias: 23797292992.638748, T: 64, Avg. loss: 405345231873051313337008128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 196141752325.89, NNZs: 1, Bias: 42103413248.010262, T: 128, Avg. loss: 321887824756583159360913408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 239788902180.48, NNZs: 1, Bias: 47573755368.088150, T: 192, Avg. loss: 271303051392974173354590208.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 229897425442.29, NNZs: 1, Bias: 27908436553.000549, T: 256, Avg. loss: 236930710262341045908930560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 100135697621.08, NNZs: 1, Bias: 22817970436.342701, T: 320, Avg. loss: 209702292738503976327053312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 5455144879.33, NNZs: 1, Bias: 29802512161.289268, T: 384, Avg. loss: 169887628616637541651578880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 16180886385.94, NNZs: 1, Bias: 23916631988.106293, T: 448, Avg. loss: 177247742201228747121623040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 64460071106.13, NNZs: 1, Bias: 5408720973.421888, T: 512, Avg. loss: 123584781765453770655793152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 64055634700.82, NNZs: 1, Bias: 15630022821.472637, T: 576, Avg. loss: 125530361166706915495903232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 52550040326.24, NNZs: 1, Bias: 20448692823.516624, T: 640, Avg. loss: 128237971816577274824622080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 157494867116.19, NNZs: 1, Bias: 14862582117.272732, T: 704, Avg. loss: 110872179725101600939704320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 135407529699.50, NNZs: 1, Bias: 18551388404.761673, T: 768, Avg. loss: 119372084691178348380946432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 114165771085.00, NNZs: 1, Bias: 19672296273.269993, T: 832, Avg. loss: 144021346459493098749689856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 14173834622.57, NNZs: 1, Bias: 19792023766.104568, T: 896, Avg. loss: 105089169585566499857235968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 129477068245.45, NNZs: 1, Bias: 36189139124.529663, T: 960, Avg. loss: 100310407425309404490104832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 6859996977.98, NNZs: 1, Bias: 49877849397.537033, T: 1024, Avg. loss: 102976008597851217856561152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 78000758446.16, NNZs: 1, Bias: 33799171170.647545, T: 1088, Avg. loss: 143083455241302160638476288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 12429166906.23, NNZs: 1, Bias: 32878262075.673141, T: 1152, Avg. loss: 99297778166323195865464832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 68986174544.15, NNZs: 1, Bias: 22699297374.818150, T: 1216, Avg. loss: 92972353511855523719282688.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 77794783563.90, NNZs: 1, Bias: 6699187058.180349, T: 1280, Avg. loss: 152820736852770747641233408.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 96339349506.30, NNZs: 1, Bias: 22931610880.261654, T: 1344, Avg. loss: 91638376669648868570300416.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 114962514513.68, NNZs: 1, Bias: 10586984236.163677, T: 1408, Avg. loss: 153406013268965404316794880.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 208630671678.52, NNZs: 1, Bias: 2841893559.145397, T: 1472, Avg. loss: 93354749536268508110782464.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 161756300379.89, NNZs: 1, Bias: 10571472647.663519, T: 1536, Avg. loss: 88957017292747433224175616.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 97469626005.93, NNZs: 1, Bias: 18481110394.013649, T: 1600, Avg. loss: 80042651998794526547247104.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 224912015523.82, NNZs: 1, Bias: 25463359658.953781, T: 1664, Avg. loss: 61140781631846430984372224.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 119959608917.06, NNZs: 1, Bias: 959644461.078079, T: 1728, Avg. loss: 87199464637925989906644992.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 120962890556.18, NNZs: 1, Bias: 5897581988.006084, T: 1792, Avg. loss: 68689839100270965612871680.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 16846652396.57, NNZs: 1, Bias: -1219978355.119472, T: 1856, Avg. loss: 93199951699347195327152128.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 24946663163.35, NNZs: 1, Bias: 22749598129.743088, T: 1920, Avg. loss: 77344829284587360684605440.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 13007590425.75, NNZs: 1, Bias: -9022431120.097780, T: 1984, Avg. loss: 72843906261970294195355648.000000\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 31 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 403785.47, NNZs: 1, Bias: -72335.232167, T: 6, Avg. loss: 9989960484320.904297\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 357388774430.32, NNZs: 1, Bias: 4947244360.256320, T: 12, Avg. loss: 102960969206672101459623936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 233390699724.60, NNZs: 1, Bias: 22788768302.506798, T: 18, Avg. loss: 1927075275855799738962018304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 934602892440.32, NNZs: 1, Bias: 4131962662.197662, T: 24, Avg. loss: 1109293967453819165688725504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 969943187033.20, NNZs: 1, Bias: -17465374622.132931, T: 30, Avg. loss: 1517646709636325031148519424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 316143373989.18, NNZs: 1, Bias: -9336082729.316732, T: 36, Avg. loss: 3233111662225752429021888512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 6 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 750069504590.72, NNZs: 1, Bias: 1532656887.127329, T: 12, Avg. loss: 87657531056021585172365312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 15315240225.54, NNZs: 1, Bias: 6120170963.995407, T: 24, Avg. loss: 3869078021354410115027959808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 274534876125.88, NNZs: 1, Bias: 15949270549.307156, T: 36, Avg. loss: 2339196348168347479435116544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 361675409932.69, NNZs: 1, Bias: 22126578345.332947, T: 48, Avg. loss: 2323977956632726508899663872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 86561760893.93, NNZs: 1, Bias: 18319893408.697243, T: 60, Avg. loss: 2156340311453665833642885120.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 131770671752.35, NNZs: 1, Bias: 35548059724.955597, T: 72, Avg. loss: 1434584556314018960675700736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 6 epochs took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 1556184602500.01, NNZs: 1, Bias: 10492107547.202074, T: 19, Avg. loss: 702104539126032742813270016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 39405609709.18, NNZs: 1, Bias: -10264445126.935324, T: 38, Avg. loss: 5548659329767504078566326272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 89644385733.23, NNZs: 1, Bias: -21239899148.711933, T: 57, Avg. loss: 2167178946617907722745544704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1014192899281.85, NNZs: 1, Bias: -8698899990.848776, T: 76, Avg. loss: 625280929861791149325287424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 15767064148.17, NNZs: 1, Bias: -30385138501.249714, T: 95, Avg. loss: 2505083481992575389873995776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 157360450209.59, NNZs: 1, Bias: -16085511155.573545, T: 114, Avg. loss: 966162095346198898968363008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 792094468103.23, NNZs: 1, Bias: -24814794186.286545, T: 133, Avg. loss: 384033189588526424488148992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 79771500284.94, NNZs: 1, Bias: -4685945195.559797, T: 152, Avg. loss: 1460444503403435665989304320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 31011225041.94, NNZs: 1, Bias: -16470139377.067923, T: 171, Avg. loss: 764334755909658767695806464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 869901257409.77, NNZs: 1, Bias: -13781263146.242653, T: 190, Avg. loss: 242106971862722193970429952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 40410145747.32, NNZs: 1, Bias: -21625895765.924644, T: 209, Avg. loss: 1737414867939922431275171840.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 170352696163.68, NNZs: 1, Bias: -45271039352.795502, T: 228, Avg. loss: 1024347867079087559286980608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 712106560666.63, NNZs: 1, Bias: -46273911475.604202, T: 247, Avg. loss: 310814965745991904034553856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 316204587854.19, NNZs: 1, Bias: -41222038529.583122, T: 266, Avg. loss: 1117675984564775980690833408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 54973665679.25, NNZs: 1, Bias: -33835248345.643833, T: 285, Avg. loss: 575858754868166221797261312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 15 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 735457730272.32, NNZs: 1, Bias: 23031508109.222023, T: 25, Avg. loss: 471007532869132450365702144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 350366037071.88, NNZs: 1, Bias: 3378267142.195188, T: 50, Avg. loss: 1298442166397640324780392448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 45634565330.96, NNZs: 1, Bias: -609304905.335870, T: 75, Avg. loss: 587352163012230873467584512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 209726944388.44, NNZs: 1, Bias: 21317802403.844887, T: 100, Avg. loss: 494752329767395152254468096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 594902863441.54, NNZs: 1, Bias: 53131005015.759697, T: 125, Avg. loss: 481758419439257336324030464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 7022217351.92, NNZs: 1, Bias: 64602223153.925926, T: 150, Avg. loss: 547011606413500734553194496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 6 epochs took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 770794306863.22, NNZs: 1, Bias: -8520377999.958142, T: 32, Avg. loss: 639621453211399213239238656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 60657887159.07, NNZs: 1, Bias: -24845236877.215439, T: 64, Avg. loss: 675979642968822663534870528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 123893363714.47, NNZs: 1, Bias: -27960270633.677685, T: 96, Avg. loss: 507837853026795804952625152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 158110903541.36, NNZs: 1, Bias: -8342439722.054863, T: 128, Avg. loss: 393768564820838117281890304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 17168741882.91, NNZs: 1, Bias: -2008397323.143593, T: 160, Avg. loss: 385147618179382092016648192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 125094459246.44, NNZs: 1, Bias: -8186521908.054613, T: 192, Avg. loss: 325606022110969848383143936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 68846903250.42, NNZs: 1, Bias: -4262210296.570151, T: 224, Avg. loss: 277231458638992054918578176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 163819781346.58, NNZs: 1, Bias: -23457827539.812057, T: 256, Avg. loss: 365726157311393162443358208.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 724426657440.97, NNZs: 1, Bias: -42761771954.749954, T: 288, Avg. loss: 205383143079090738289442816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 253673860398.37, NNZs: 1, Bias: -40166316212.408379, T: 320, Avg. loss: 485972202917761198724218880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 627587560466.65, NNZs: 1, Bias: -40753458526.852837, T: 352, Avg. loss: 168481904898557804380422144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 163279267645.26, NNZs: 1, Bias: -49528359534.376755, T: 384, Avg. loss: 346825360608159700713734144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 21661360658.97, NNZs: 1, Bias: -50123729904.813217, T: 416, Avg. loss: 228206282839260408372527104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 415704717004.28, NNZs: 1, Bias: -30483650869.519772, T: 448, Avg. loss: 196835544004754700119310336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 25887346887.16, NNZs: 1, Bias: -35577534812.526939, T: 480, Avg. loss: 290920279710427637587378176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 237304748799.97, NNZs: 1, Bias: -20644293331.454567, T: 512, Avg. loss: 217068933038279954014404608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 16 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 2691537719.13, NNZs: 1, Bias: -1283845269.737254, T: 38, Avg. loss: 794790454673679719830913024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 72633745409.61, NNZs: 1, Bias: -10644548882.521452, T: 76, Avg. loss: 542160060396523401349431296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 51584768098.26, NNZs: 1, Bias: 16508455210.843927, T: 114, Avg. loss: 499387640711311168297238528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 60926880866.00, NNZs: 1, Bias: -11375051457.880983, T: 152, Avg. loss: 339136298711170738007572480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 55534613459.49, NNZs: 1, Bias: -23233049118.558887, T: 190, Avg. loss: 293714827997069897768108032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 19306781432.35, NNZs: 1, Bias: -38187922977.485153, T: 228, Avg. loss: 247595943165224263559938048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 214509212326.84, NNZs: 1, Bias: -31343327296.742321, T: 266, Avg. loss: 229312225340090119981367296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 768824336317.50, NNZs: 1, Bias: -17751072296.494194, T: 304, Avg. loss: 129891518004833639204913152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 549747853419.37, NNZs: 1, Bias: -35715489837.755547, T: 342, Avg. loss: 356199153866535202776416256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 177727783327.53, NNZs: 1, Bias: -49999671695.810516, T: 380, Avg. loss: 320696544388186831272804352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 9292059676.33, NNZs: 1, Bias: -61121915055.150185, T: 418, Avg. loss: 176833368177449834949640192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 177336987854.41, NNZs: 1, Bias: -60749873068.661163, T: 456, Avg. loss: 136730838995608859981119488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 1418337599.97, NNZs: 1, Bias: -58605248102.447716, T: 494, Avg. loss: 172931960378844099318382592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 13 epochs took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 155084482242.10, NNZs: 1, Bias: -35329331105.854286, T: 44, Avg. loss: 1136983280779606643632504832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 104143152877.47, NNZs: 1, Bias: -37868152345.735542, T: 88, Avg. loss: 887644492313343348067794944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 178822685627.98, NNZs: 1, Bias: -54657186822.132286, T: 132, Avg. loss: 416141091944191395106914304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 309157984660.10, NNZs: 1, Bias: -41122038712.366737, T: 176, Avg. loss: 431255366225838914691661824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 270305774523.27, NNZs: 1, Bias: -42476998966.189041, T: 220, Avg. loss: 404679191548803372913000448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 199059544014.35, NNZs: 1, Bias: -40293021091.593246, T: 264, Avg. loss: 396136079579479856734273536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 331107340408.26, NNZs: 1, Bias: -34429792335.479118, T: 308, Avg. loss: 308879463849717185189511168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 94036113151.64, NNZs: 1, Bias: -16895880188.485123, T: 352, Avg. loss: 408547888027790706504368128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1875695832.89, NNZs: 1, Bias: -23713445549.378845, T: 396, Avg. loss: 180167168198951237654151168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 235688212148.84, NNZs: 1, Bias: -33352307666.744614, T: 440, Avg. loss: 183795136868320438650929152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 27248233618.91, NNZs: 1, Bias: -21749708783.246796, T: 484, Avg. loss: 302625293377565974945857536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 317892897713.38, NNZs: 1, Bias: -27111066105.053284, T: 528, Avg. loss: 169047258364880106890985472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 119867870259.70, NNZs: 1, Bias: -29500494583.205673, T: 572, Avg. loss: 243338611884902590541987840.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 325295516420.58, NNZs: 1, Bias: -27556310392.431713, T: 616, Avg. loss: 162791843112235832098947072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 25182834030.46, NNZs: 1, Bias: -29685031969.156727, T: 660, Avg. loss: 248769644243215825485430784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 90343066968.88, NNZs: 1, Bias: -46533367076.213203, T: 704, Avg. loss: 207211906403782442222616576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 331977553569.72, NNZs: 1, Bias: -39941672644.479622, T: 748, Avg. loss: 169037469237872631388045312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 121910152142.79, NNZs: 1, Bias: -40990271586.168205, T: 792, Avg. loss: 147369147136866509660356608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 292034827335.97, NNZs: 1, Bias: -49578110914.156166, T: 836, Avg. loss: 164115190358213035483463680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 107885998666.45, NNZs: 1, Bias: -69577990446.049850, T: 880, Avg. loss: 164645288288587883363696640.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 257364561281.96, NNZs: 1, Bias: -67628805196.871063, T: 924, Avg. loss: 113882403798617430649995264.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 1888285038.34, NNZs: 1, Bias: -62153492662.674316, T: 968, Avg. loss: 220432099754627163635056640.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 144245498341.53, NNZs: 1, Bias: -81277525161.066620, T: 1012, Avg. loss: 125178191002493459170852864.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 32772181358.78, NNZs: 1, Bias: -84753017788.683441, T: 1056, Avg. loss: 201528944241274049202749440.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 79901508064.27, NNZs: 1, Bias: -84980432271.610825, T: 1100, Avg. loss: 172179481246187283399311360.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 212874320454.28, NNZs: 1, Bias: -84135293725.631027, T: 1144, Avg. loss: 153744349124196042750820352.000000\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 26 epochs took 0.01 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 611803592215.22, NNZs: 1, Bias: 61972012576.112755, T: 51, Avg. loss: 480397683296688198792511488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 310371648437.79, NNZs: 1, Bias: 61894914180.427048, T: 102, Avg. loss: 466386562148161604661805056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 285683896083.79, NNZs: 1, Bias: 39918719330.331657, T: 153, Avg. loss: 666189580154423172053073920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 6797515849.21, NNZs: 1, Bias: 17576315210.831947, T: 204, Avg. loss: 461490867563356880317186048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 226939240666.00, NNZs: 1, Bias: 12665254328.424675, T: 255, Avg. loss: 306780014283337274916601856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 51080802763.79, NNZs: 1, Bias: 48034664604.577744, T: 306, Avg. loss: 269446358384040650668507136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 380351029737.99, NNZs: 1, Bias: 51867261323.865906, T: 357, Avg. loss: 200303837606627182813118464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 93573420552.29, NNZs: 1, Bias: 32100991564.406548, T: 408, Avg. loss: 188342367495470113263452160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 228543272150.79, NNZs: 1, Bias: 42439860429.939491, T: 459, Avg. loss: 248878571563072051342213120.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 180334280413.59, NNZs: 1, Bias: 52435508681.391899, T: 510, Avg. loss: 138315716904603117535887360.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 47563520017.74, NNZs: 1, Bias: 71021863542.486893, T: 561, Avg. loss: 195395225861066595843964928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 94051722468.95, NNZs: 1, Bias: 46869684362.639465, T: 612, Avg. loss: 142309219934299297415168000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 107549196477.82, NNZs: 1, Bias: 30591327445.899456, T: 663, Avg. loss: 169465719796552211919536128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 170468289112.69, NNZs: 1, Bias: 22445910220.181427, T: 714, Avg. loss: 139329645030242882198437888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 118381417934.97, NNZs: 1, Bias: 36037820717.354279, T: 765, Avg. loss: 188850254064375170995322880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 15 epochs took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 80766745444.82, NNZs: 1, Bias: -29425306694.880440, T: 57, Avg. loss: 420223293715375217516216320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 51362914412.38, NNZs: 1, Bias: -37367660027.393669, T: 114, Avg. loss: 431908171277034167386243072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 40524492905.96, NNZs: 1, Bias: -60954143463.455612, T: 171, Avg. loss: 338790031842250590710136832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 45993595264.68, NNZs: 1, Bias: -60719194846.136520, T: 228, Avg. loss: 210210872044422293264269312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 209448761851.33, NNZs: 1, Bias: -50074506369.257164, T: 285, Avg. loss: 219452311989854798436368384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 107885294067.84, NNZs: 1, Bias: -55038554780.998138, T: 342, Avg. loss: 215001348288690145395212288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 204557701410.12, NNZs: 1, Bias: -48754999305.070839, T: 399, Avg. loss: 263423191444760746396745728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 504266306950.28, NNZs: 1, Bias: -38528933269.746872, T: 456, Avg. loss: 135948603808164309702279168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 20549773868.69, NNZs: 1, Bias: -34631988028.830399, T: 513, Avg. loss: 167541867543531326514659328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 128413490286.48, NNZs: 1, Bias: -36219386107.215508, T: 570, Avg. loss: 138701995127444036296638464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 240760976720.41, NNZs: 1, Bias: -42655445318.120964, T: 627, Avg. loss: 144398063493570044423569408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 3246402082.68, NNZs: 1, Bias: -69908512251.672241, T: 684, Avg. loss: 138828068188894339700621312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 207565399803.38, NNZs: 1, Bias: -81714694889.053665, T: 741, Avg. loss: 100622553899684347055702016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 120158062268.14, NNZs: 1, Bias: -64769860141.609886, T: 798, Avg. loss: 120003187686819437249298432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 230705549162.07, NNZs: 1, Bias: -68263677748.911652, T: 855, Avg. loss: 120290827717456748678742016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 15926192582.26, NNZs: 1, Bias: -73972779444.944016, T: 912, Avg. loss: 141168932045043258290601984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 39206668129.75, NNZs: 1, Bias: -60180155515.090858, T: 969, Avg. loss: 178883951917821851061977088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 166455758711.05, NNZs: 1, Bias: -53430455153.451202, T: 1026, Avg. loss: 197167748917666190454685696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 18 epochs took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 32161601696.96, NNZs: 1, Bias: -23885324066.334007, T: 64, Avg. loss: 576150520231318044945678336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 123097585296.64, NNZs: 1, Bias: -67049682300.174866, T: 128, Avg. loss: 484096195914602907411939328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 341419055262.25, NNZs: 1, Bias: -39405514262.945786, T: 192, Avg. loss: 327154238470510685726965760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 79166740783.28, NNZs: 1, Bias: -65835108019.688347, T: 256, Avg. loss: 230752659689846392081088512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 40489897379.29, NNZs: 1, Bias: -69817888971.192963, T: 320, Avg. loss: 199564018356169816420646912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 277598716926.04, NNZs: 1, Bias: -70817663080.568298, T: 384, Avg. loss: 152955901424530969046548480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 571092474299.89, NNZs: 1, Bias: -70702415134.909470, T: 448, Avg. loss: 133807041689490533707153408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 280707361443.56, NNZs: 1, Bias: -48890998595.846428, T: 512, Avg. loss: 209563217899232037424857088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 172569944870.84, NNZs: 1, Bias: -31103642031.958813, T: 576, Avg. loss: 173431737337360487668514816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 31059097453.40, NNZs: 1, Bias: -52712811492.766541, T: 640, Avg. loss: 139190665874349996780814336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 3961768637.18, NNZs: 1, Bias: -38838933604.708336, T: 704, Avg. loss: 118143112069504284078637056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 42017386399.82, NNZs: 1, Bias: -32174955649.869816, T: 768, Avg. loss: 151398205437664489864429568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 64989193390.93, NNZs: 1, Bias: -18109858045.639679, T: 832, Avg. loss: 129574719544962241999667200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 28995404947.35, NNZs: 1, Bias: -35156249282.601799, T: 896, Avg. loss: 110341984478351930490355712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 164962985207.14, NNZs: 1, Bias: -29524805569.714088, T: 960, Avg. loss: 93070172579669853821992960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 54304536724.74, NNZs: 1, Bias: -17160946388.609554, T: 1024, Avg. loss: 152551193736845298159845376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 419742527.62, NNZs: 1, Bias: 76273912.926924, T: 1088, Avg. loss: 125168236399138577798135808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 184201771739.16, NNZs: 1, Bias: -8729118468.828812, T: 1152, Avg. loss: 124886648198035589702877184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 51913652746.74, NNZs: 1, Bias: 594053874.223293, T: 1216, Avg. loss: 132761008468028362829332480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 151949304293.13, NNZs: 1, Bias: 9175571100.928848, T: 1280, Avg. loss: 99697670095138969538789376.000000\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 20 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 7904369.68, NNZs: 1, Bias: 84364.919872, T: 6, Avg. loss: 15168314343822.312500\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 129510599087.74, NNZs: 1, Bias: -436952817.644663, T: 12, Avg. loss: 180151728534175186367283200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 685124172216.73, NNZs: 1, Bias: -20394660960.226128, T: 18, Avg. loss: 2196143289338850240494567424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1229664066956.12, NNZs: 1, Bias: -30629832575.149754, T: 24, Avg. loss: 592367524773935956531085312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 294773159021.27, NNZs: 1, Bias: -21577182640.051880, T: 30, Avg. loss: 9434674139085675599086223360.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 296226711411.22, NNZs: 1, Bias: 3372605298.287765, T: 36, Avg. loss: 1805291125505606174432559104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 6 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 358670973130.83, NNZs: 1, Bias: 646143344.531386, T: 12, Avg. loss: 422640782886042281529311232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 94365481923.60, NNZs: 1, Bias: 6132848145.658325, T: 24, Avg. loss: 4903153870840872461976731648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 610470943214.04, NNZs: 1, Bias: -12699877165.722137, T: 36, Avg. loss: 1279888613050928264382513152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 952880516716.84, NNZs: 1, Bias: -23971774850.256332, T: 48, Avg. loss: 1636810450122476560735797248.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 487014411944.24, NNZs: 1, Bias: -12590245109.676405, T: 60, Avg. loss: 1359690887947663554193129472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 128169020617.14, NNZs: 1, Bias: 12519988446.992722, T: 72, Avg. loss: 1620684118083247887326642176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 6 epochs took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 427836850981.50, NNZs: 1, Bias: 23675537909.092407, T: 19, Avg. loss: 1410839259513949600419414016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 339714730718.83, NNZs: 1, Bias: 21478272906.455132, T: 38, Avg. loss: 1337532306173242631608336384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1003561028198.59, NNZs: 1, Bias: 25332033654.413681, T: 57, Avg. loss: 810045446550963880070217728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 538552975673.64, NNZs: 1, Bias: 36139731236.574013, T: 76, Avg. loss: 1381016195659451495096516608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 184591041301.68, NNZs: 1, Bias: 14115042490.100210, T: 95, Avg. loss: 983068452978027310012694528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 29213882240.39, NNZs: 1, Bias: 23644010258.169399, T: 114, Avg. loss: 1066739677770408643147071488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 418715017851.06, NNZs: 1, Bias: 20813039502.555000, T: 133, Avg. loss: 1321144964561837233300045824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 305825587415.18, NNZs: 1, Bias: -8596775585.326847, T: 152, Avg. loss: 741478729806994803940917248.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 607466268306.95, NNZs: 1, Bias: -5931521836.281561, T: 171, Avg. loss: 388563605025926470405455872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 396146738904.93, NNZs: 1, Bias: 2206179507.063095, T: 190, Avg. loss: 571304165487146214342262784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 32857954491.80, NNZs: 1, Bias: -341329385.568884, T: 209, Avg. loss: 489903723037570249795829760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 167634210824.60, NNZs: 1, Bias: -2975417085.235909, T: 228, Avg. loss: 714462921068201537947303936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 72203897255.81, NNZs: 1, Bias: 4621115930.817537, T: 247, Avg. loss: 716446065882829403902181376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 113758085941.97, NNZs: 1, Bias: -10365835617.589018, T: 266, Avg. loss: 564874748572490012718792704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 14 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 670926633276.50, NNZs: 1, Bias: -14355281951.723143, T: 25, Avg. loss: 2437360513938577617724637184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 435633877783.96, NNZs: 1, Bias: -20072518387.224884, T: 50, Avg. loss: 1174203782014815020691488768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 542969305983.34, NNZs: 1, Bias: -1548332684.409629, T: 75, Avg. loss: 523485353424625135010185216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 971597372542.44, NNZs: 1, Bias: 1796410842.322654, T: 100, Avg. loss: 369435876436974511853666304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 210745775943.23, NNZs: 1, Bias: -11667729162.036446, T: 125, Avg. loss: 1035548550580154956311953408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 485715869839.64, NNZs: 1, Bias: -15596885529.365364, T: 150, Avg. loss: 561372036796930044217786368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 173708132812.91, NNZs: 1, Bias: -20333359722.011528, T: 175, Avg. loss: 588690029345004991337725952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 15170636076.76, NNZs: 1, Bias: -53508643855.881149, T: 200, Avg. loss: 345771341945460043915722752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 142478505728.90, NNZs: 1, Bias: -45463152198.067299, T: 225, Avg. loss: 379637257896069457921441792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 16243435609.05, NNZs: 1, Bias: -50263233172.374290, T: 250, Avg. loss: 429720658658126028496437248.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 343000199540.62, NNZs: 1, Bias: -60591717139.853264, T: 275, Avg. loss: 264762369752703210725834752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 133099053008.55, NNZs: 1, Bias: -44897791130.600433, T: 300, Avg. loss: 430682480908590567401717760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 176026160442.54, NNZs: 1, Bias: -50488075590.172028, T: 325, Avg. loss: 362015432433614709109817344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 59083903272.58, NNZs: 1, Bias: -40709362130.723663, T: 350, Avg. loss: 473279399390925423640576000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 56388933630.09, NNZs: 1, Bias: -30491663367.909134, T: 375, Avg. loss: 236611331818110884438343680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 150602915300.65, NNZs: 1, Bias: -22996638807.685772, T: 400, Avg. loss: 487964061755513238093561856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 232074559811.09, NNZs: 1, Bias: -37528106687.301727, T: 425, Avg. loss: 265116658252863000731975680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 281779487660.72, NNZs: 1, Bias: -21566119811.015472, T: 450, Avg. loss: 531216276442287171168108544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 252149912923.06, NNZs: 1, Bias: -23299323206.191895, T: 475, Avg. loss: 360474319359947988331921408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 337601355019.15, NNZs: 1, Bias: -25458641771.487206, T: 500, Avg. loss: 226054945490812326964625408.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 623716092564.62, NNZs: 1, Bias: -16724861507.095888, T: 525, Avg. loss: 173442263164659420486434816.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 83104790790.72, NNZs: 1, Bias: -612956009.123966, T: 550, Avg. loss: 351793965180118334064033792.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 224325640555.14, NNZs: 1, Bias: -29969132.194051, T: 575, Avg. loss: 204672333537070037738717184.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 122422516629.23, NNZs: 1, Bias: -2041730256.982166, T: 600, Avg. loss: 295114248155289096005091328.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 105489984655.44, NNZs: 1, Bias: -34112886146.927193, T: 625, Avg. loss: 211136135322321390265171968.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 83258954339.87, NNZs: 1, Bias: -32090493072.268288, T: 650, Avg. loss: 230282803938725249515782144.000000\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 26 epochs took 0.01 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 75580538237.08, NNZs: 1, Bias: -32403003051.934185, T: 32, Avg. loss: 341492156837375233870528512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 292741626915.68, NNZs: 1, Bias: -26004852856.244835, T: 64, Avg. loss: 624627845651645115970617344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 143952968807.98, NNZs: 1, Bias: -59786032002.295349, T: 96, Avg. loss: 456593898385834295452237824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 3098271308.31, NNZs: 1, Bias: -61475708651.433151, T: 128, Avg. loss: 486623321489026774542057472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 197527550464.57, NNZs: 1, Bias: -30812136531.271767, T: 160, Avg. loss: 224028337849795973228789760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 120534390971.05, NNZs: 1, Bias: -37658928893.959763, T: 192, Avg. loss: 478598849240297412451368960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 58915823539.64, NNZs: 1, Bias: 9688601256.669806, T: 224, Avg. loss: 245962546306950881553154048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 122778860939.59, NNZs: 1, Bias: 11756769360.175385, T: 256, Avg. loss: 274658105809505247461113856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 232150799788.51, NNZs: 1, Bias: 8670809135.104881, T: 288, Avg. loss: 308837618805230361364135936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 11074199326.82, NNZs: 1, Bias: 3178430209.534223, T: 320, Avg. loss: 280411985537249575331430400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 10 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 23891490245.31, NNZs: 1, Bias: 43610902298.221825, T: 38, Avg. loss: 553263245229443716969660416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 173111361108.87, NNZs: 1, Bias: 32486782729.978970, T: 76, Avg. loss: 674943914085752507088240640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 242488732900.46, NNZs: 1, Bias: 9363748542.587942, T: 114, Avg. loss: 243036078602405274779123712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 63218585058.39, NNZs: 1, Bias: 32642775623.386711, T: 152, Avg. loss: 508263472293329636962598912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2831807745.62, NNZs: 1, Bias: 30708285935.916996, T: 190, Avg. loss: 368725669423045261985316864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2348721663.65, NNZs: 1, Bias: 16128317023.782879, T: 228, Avg. loss: 180970762061228319367495680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 317297335974.78, NNZs: 1, Bias: 22183324988.019836, T: 266, Avg. loss: 204977740350534946480193536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 30119564158.94, NNZs: 1, Bias: 14469066370.493973, T: 304, Avg. loss: 197367844141302109419077632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 288859755705.10, NNZs: 1, Bias: 42574267855.002251, T: 342, Avg. loss: 182173123120040894225448960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 65095215419.61, NNZs: 1, Bias: 54227110597.133926, T: 380, Avg. loss: 222345709804298935176527872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 616247203031.84, NNZs: 1, Bias: 55386321976.617561, T: 418, Avg. loss: 90961425211351199387746304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 2432725524.23, NNZs: 1, Bias: 67245800191.968025, T: 456, Avg. loss: 335533914289337198532624384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 63637360720.99, NNZs: 1, Bias: 75339596952.817886, T: 494, Avg. loss: 153241539458229144955912192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 245612784731.06, NNZs: 1, Bias: 59643452815.083397, T: 532, Avg. loss: 194506430083906785161248768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 118453237636.53, NNZs: 1, Bias: 72765049614.582504, T: 570, Avg. loss: 140735820951929583342452736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 604273816.25, NNZs: 1, Bias: 73064067327.041794, T: 608, Avg. loss: 131440734352990485902000128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 16 epochs took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 115942003467.39, NNZs: 1, Bias: -2118480600.699285, T: 44, Avg. loss: 288630061759994437784567808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 117988044436.13, NNZs: 1, Bias: -15008093642.617622, T: 88, Avg. loss: 530037486695101835321016320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 34430176155.12, NNZs: 1, Bias: -9145736890.402557, T: 132, Avg. loss: 309074127305791510759342080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 334877883502.03, NNZs: 1, Bias: -15595877174.594011, T: 176, Avg. loss: 271104123340841211679211520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 4911988328.70, NNZs: 1, Bias: -47276768046.045494, T: 220, Avg. loss: 162859979579000095743410176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 28539694884.53, NNZs: 1, Bias: -20269346845.286690, T: 264, Avg. loss: 164158629692868020473430016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 40530153367.58, NNZs: 1, Bias: -27050180975.645615, T: 308, Avg. loss: 147556108395368277021294592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 24330115106.98, NNZs: 1, Bias: -23548380178.874794, T: 352, Avg. loss: 202984811128140160116457472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 157900139924.50, NNZs: 1, Bias: -28062652152.202286, T: 396, Avg. loss: 123936754000413376232030208.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 327128635782.77, NNZs: 1, Bias: -30483905680.053307, T: 440, Avg. loss: 47204340031538648032739328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 108994058069.18, NNZs: 1, Bias: -20818492416.818958, T: 484, Avg. loss: 159788953519482571969265664.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 32592912359.32, NNZs: 1, Bias: -20412092704.416309, T: 528, Avg. loss: 196443657333678036005945344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 24587189082.13, NNZs: 1, Bias: -10264005536.987757, T: 572, Avg. loss: 111758335915857924111466496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 24191758760.27, NNZs: 1, Bias: 207704922.368647, T: 616, Avg. loss: 162590610682172834653929472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 12856658725.43, NNZs: 1, Bias: -844725775.261415, T: 660, Avg. loss: 92461362318103890358173696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 15 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 212551183046.36, NNZs: 1, Bias: 20026080808.023121, T: 51, Avg. loss: 421965306834924634076348416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 244488450028.71, NNZs: 1, Bias: 81488264592.234833, T: 102, Avg. loss: 597246542270721852706914304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 345594816489.77, NNZs: 1, Bias: 69668324830.073502, T: 153, Avg. loss: 265128118882737438016405504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 188988759842.06, NNZs: 1, Bias: 77737281468.493515, T: 204, Avg. loss: 186775520164934234799079424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 211195953777.27, NNZs: 1, Bias: 122934972169.362167, T: 255, Avg. loss: 192466869305929286937477120.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 417445749842.09, NNZs: 1, Bias: 136352655157.553070, T: 306, Avg. loss: 242882340129532238553415680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 57536466871.05, NNZs: 1, Bias: 127424710283.001770, T: 357, Avg. loss: 205184993571467465286746112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 59705242225.19, NNZs: 1, Bias: 113454368821.076736, T: 408, Avg. loss: 139463656704213347660201984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 59544432516.07, NNZs: 1, Bias: 92968503729.307449, T: 459, Avg. loss: 153606007079857496046698496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 34180673442.25, NNZs: 1, Bias: 81378044056.869629, T: 510, Avg. loss: 190899794309938380131008512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 94102449387.50, NNZs: 1, Bias: 51711498321.778564, T: 561, Avg. loss: 215157666762471021813432320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 133399200566.37, NNZs: 1, Bias: 48068007271.337372, T: 612, Avg. loss: 102775831215915790699069440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 14888647400.77, NNZs: 1, Bias: 59059214664.105362, T: 663, Avg. loss: 136021862167984716088606720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 91271849291.56, NNZs: 1, Bias: 60287806469.518639, T: 714, Avg. loss: 85765500507083906522021888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 109381718600.69, NNZs: 1, Bias: 61515206126.029884, T: 765, Avg. loss: 81005126673154752584351744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 59213445276.38, NNZs: 1, Bias: 80854851304.186508, T: 816, Avg. loss: 90811318851124697715703808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 7469752256.78, NNZs: 1, Bias: 92535017475.346436, T: 867, Avg. loss: 94824434127814947646734336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 289794815167.06, NNZs: 1, Bias: 97354912500.962601, T: 918, Avg. loss: 62375006726319256434114560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 114034353905.59, NNZs: 1, Bias: 77726689940.438522, T: 969, Avg. loss: 84205912547860735026266112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 182926621751.18, NNZs: 1, Bias: 72377586704.876480, T: 1020, Avg. loss: 101488785268014544110747648.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 117337638154.69, NNZs: 1, Bias: 71521527379.909851, T: 1071, Avg. loss: 68862189633222305789247488.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 438576822024.71, NNZs: 1, Bias: 64235169024.791718, T: 1122, Avg. loss: 49177853993717179481063424.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 37537648429.58, NNZs: 1, Bias: 70387341258.800125, T: 1173, Avg. loss: 134188329215643230312333312.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 186035397795.79, NNZs: 1, Bias: 61990702919.574211, T: 1224, Avg. loss: 83243067287422379724111872.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 48225455027.68, NNZs: 1, Bias: 80690865385.365051, T: 1275, Avg. loss: 175987059636534107854340096.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 5264420657.54, NNZs: 1, Bias: 62186579142.851143, T: 1326, Avg. loss: 74782670374120923051589632.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 13718831363.29, NNZs: 1, Bias: 53132764510.936455, T: 1377, Avg. loss: 74458720311188077513015296.000000\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 27 epochs took 0.01 seconds\n",
      "-- Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 92158932574.20, NNZs: 1, Bias: -34950851654.059860, T: 57, Avg. loss: 371463553868785011600130048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 283627087354.53, NNZs: 1, Bias: -26586743260.514595, T: 114, Avg. loss: 213081195568070538408493056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 184527023069.35, NNZs: 1, Bias: 2912013652.492053, T: 171, Avg. loss: 260261781336764223164776448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 108624359237.50, NNZs: 1, Bias: -13410025870.002569, T: 228, Avg. loss: 224762476127865433684443136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 90702928304.01, NNZs: 1, Bias: -9507772252.826437, T: 285, Avg. loss: 166489991308444615542046720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 108149618327.12, NNZs: 1, Bias: -38190149602.532326, T: 342, Avg. loss: 229703301062038899132465152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 36415916893.34, NNZs: 1, Bias: -24768765280.781975, T: 399, Avg. loss: 127281018966505157835096064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 679577250138.93, NNZs: 1, Bias: -9897840364.329481, T: 456, Avg. loss: 60390096463545402122043392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 11189247405.30, NNZs: 1, Bias: -16635743558.281767, T: 513, Avg. loss: 279819771237416090545946624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 63539648669.88, NNZs: 1, Bias: -10210501479.190596, T: 570, Avg. loss: 113386400517630269012836352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 189318240609.98, NNZs: 1, Bias: -22592066887.780907, T: 627, Avg. loss: 135900180458600732530049024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 58655344189.36, NNZs: 1, Bias: -6177256312.102337, T: 684, Avg. loss: 95279638610173842365087744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 1940892513.85, NNZs: 1, Bias: -4489015423.100825, T: 741, Avg. loss: 151966931344231364751785984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 13 epochs took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 624465536025.86, NNZs: 1, Bias: -18321830972.419548, T: 64, Avg. loss: 305323046548320449627947008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 116339006500.77, NNZs: 1, Bias: -15951926964.135305, T: 128, Avg. loss: 299161565388531999442993152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 87449817457.04, NNZs: 1, Bias: -8977713008.188646, T: 192, Avg. loss: 223381816690207630515240960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 370098796013.96, NNZs: 1, Bias: 6399663898.785412, T: 256, Avg. loss: 155602425043416970162077696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 29333332757.54, NNZs: 1, Bias: 14408016078.253357, T: 320, Avg. loss: 143917370969498589801218048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 217663109320.05, NNZs: 1, Bias: 15557264862.017929, T: 384, Avg. loss: 143483362345742897376133120.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 325894991876.18, NNZs: 1, Bias: -897192216.911349, T: 448, Avg. loss: 129585007064178539072847872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 5933743432.61, NNZs: 1, Bias: -24896054900.508324, T: 512, Avg. loss: 157108496396500961272528896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 92120418744.91, NNZs: 1, Bias: -39585484437.463867, T: 576, Avg. loss: 102191134518461888175538176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 58372104522.53, NNZs: 1, Bias: 3034447922.824900, T: 640, Avg. loss: 87319215550753398604169216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 17421464469.26, NNZs: 1, Bias: -4275873554.835248, T: 704, Avg. loss: 104886682811146003806158848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 110334079315.47, NNZs: 1, Bias: -18568561947.072853, T: 768, Avg. loss: 89461625106558110524243968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 210139202670.82, NNZs: 1, Bias: -26071299562.064228, T: 832, Avg. loss: 104466795791669393803444224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 196093626758.09, NNZs: 1, Bias: -34758630359.414009, T: 896, Avg. loss: 94399994959798424500699136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 217943963427.16, NNZs: 1, Bias: -27679273157.941898, T: 960, Avg. loss: 89696009027772379010433024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 15 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 649054.93, NNZs: 1, Bias: 2248.562448, T: 6, Avg. loss: 10202433545.667162\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1516693631588.42, NNZs: 1, Bias: 5864139645.209263, T: 12, Avg. loss: 14961059480446395062681600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1269383418501.14, NNZs: 1, Bias: 25998655903.841846, T: 18, Avg. loss: 3032944935062945150296653824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1049816682239.92, NNZs: 1, Bias: 44432778073.001289, T: 24, Avg. loss: 2622480790198224633599098880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 861619453026.54, NNZs: 1, Bias: 61705372615.202805, T: 30, Avg. loss: 2115209345541127256913477632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 923428650983.51, NNZs: 1, Bias: 61922999509.031784, T: 36, Avg. loss: 1303855963797550105140133888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 6 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 595599231751.72, NNZs: 1, Bias: -6275253463.916952, T: 12, Avg. loss: 63906738963733765530058752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 54292320503.40, NNZs: 1, Bias: -20068119391.291004, T: 24, Avg. loss: 4100898679822805377220608000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 723252665982.47, NNZs: 1, Bias: -7055458391.111088, T: 36, Avg. loss: 1175561361244250315310497792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 518729169689.62, NNZs: 1, Bias: 5692987859.517839, T: 48, Avg. loss: 1877967761052854597762154496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 613696636854.51, NNZs: 1, Bias: -4647354446.623291, T: 60, Avg. loss: 1071116351796291472405299200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 599086822029.79, NNZs: 1, Bias: 13201464488.423000, T: 72, Avg. loss: 1874014355010675468195069952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 6 epochs took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 27611587652.89, NNZs: 1, Bias: -15183160210.294859, T: 19, Avg. loss: 427155275272479502074118144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 407661758366.44, NNZs: 1, Bias: -496942477.797909, T: 38, Avg. loss: 1753251120349018065280696320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 58898731205.97, NNZs: 1, Bias: 19235685101.977177, T: 57, Avg. loss: 1412215853131166279421394944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 770781646162.35, NNZs: 1, Bias: 35387168158.869247, T: 76, Avg. loss: 610854665588615663857958912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 378033799839.93, NNZs: 1, Bias: 51143183966.398041, T: 95, Avg. loss: 1366153662712198701154041856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 98713814346.35, NNZs: 1, Bias: 73207576461.826736, T: 114, Avg. loss: 763364219745131850685743104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 6 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 52740946392.01, NNZs: 1, Bias: 25410751561.197960, T: 25, Avg. loss: 2457419265192690229358624768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 31153712181.85, NNZs: 1, Bias: 36975847903.791931, T: 50, Avg. loss: 977917048171567685834899456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 59139026745.61, NNZs: 1, Bias: 46756248055.106117, T: 75, Avg. loss: 1065589525687028044124913664.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 69104556706.13, NNZs: 1, Bias: 30442996181.216049, T: 100, Avg. loss: 526366587699790128707796992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 259243138063.89, NNZs: 1, Bias: 31712101841.641140, T: 125, Avg. loss: 335380122035142754222211072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 72817444158.55, NNZs: 1, Bias: 28724841319.685066, T: 150, Avg. loss: 480858999219605336158633984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 222610886914.22, NNZs: 1, Bias: 27765470452.726654, T: 175, Avg. loss: 548006334499963999250022400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 356422969513.89, NNZs: 1, Bias: 25865937979.363800, T: 200, Avg. loss: 354149685556552470320119808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 148961867397.25, NNZs: 1, Bias: 19305402334.113842, T: 225, Avg. loss: 498444845719298373020811264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 54036958703.97, NNZs: 1, Bias: 19118483751.981468, T: 250, Avg. loss: 491327932197682636226822144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 10 epochs took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 189820251452.73, NNZs: 1, Bias: 4347499580.290134, T: 32, Avg. loss: 1048987680649634621016768512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 500984066865.45, NNZs: 1, Bias: 35799384414.799873, T: 64, Avg. loss: 577362919068488018411126784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 644603995836.08, NNZs: 1, Bias: 61447583551.178787, T: 96, Avg. loss: 618130354053002786148188160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 44043107425.86, NNZs: 1, Bias: 103163628129.413452, T: 128, Avg. loss: 534298823538521338567196672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 212691600694.06, NNZs: 1, Bias: 105391882145.577209, T: 160, Avg. loss: 565374187886029888144015360.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 168857638324.74, NNZs: 1, Bias: 109116170606.810135, T: 192, Avg. loss: 359968260603603482816020480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 149077012765.10, NNZs: 1, Bias: 113254599516.180786, T: 224, Avg. loss: 289333455278219306240835584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 799538471550.98, NNZs: 1, Bias: 125332694010.584076, T: 256, Avg. loss: 144616156223938511375433728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 59274153841.54, NNZs: 1, Bias: 126183391310.080765, T: 288, Avg. loss: 538635633367420998336380928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 41530405744.21, NNZs: 1, Bias: 123537578476.523270, T: 320, Avg. loss: 290393617245859314380308480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 52007881431.93, NNZs: 1, Bias: 112302936936.822983, T: 352, Avg. loss: 240141293752692017299718144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 174229221721.77, NNZs: 1, Bias: 108245883157.298141, T: 384, Avg. loss: 297647092668148899851010048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 38694144373.21, NNZs: 1, Bias: 117222231288.231735, T: 416, Avg. loss: 216898043729030068591132672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 13 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 221791599098.00, NNZs: 1, Bias: -19585922577.888588, T: 38, Avg. loss: 380358374622182058460446720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 225636898566.74, NNZs: 1, Bias: 748659011.195820, T: 76, Avg. loss: 667057363918078261699018752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 71897434290.88, NNZs: 1, Bias: 13808694096.403471, T: 114, Avg. loss: 510610763561265677192921088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 126295642866.73, NNZs: 1, Bias: 4498441752.433371, T: 152, Avg. loss: 209107934718589736163737600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 122878991498.51, NNZs: 1, Bias: -1081718099.558355, T: 190, Avg. loss: 384335930035007806307827712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 260531814628.80, NNZs: 1, Bias: -20275760288.944839, T: 228, Avg. loss: 237023742870590058917789696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 289189441818.16, NNZs: 1, Bias: -26744347117.202522, T: 266, Avg. loss: 199975690340143730853412864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 62449538740.04, NNZs: 1, Bias: -28880530074.778805, T: 304, Avg. loss: 254901387483115323264073728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 270644917611.40, NNZs: 1, Bias: -27926584507.147240, T: 342, Avg. loss: 174868661742079014227410944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 151715015322.66, NNZs: 1, Bias: -19241662773.320541, T: 380, Avg. loss: 211581030657386923079761920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 144797486587.63, NNZs: 1, Bias: -22110619775.665859, T: 418, Avg. loss: 147770993590850682217299968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 124169018487.81, NNZs: 1, Bias: -18951920608.065434, T: 456, Avg. loss: 140942695537382113281048576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 295807408259.89, NNZs: 1, Bias: -30163065269.627464, T: 494, Avg. loss: 170096957868024877123895296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 97414620842.36, NNZs: 1, Bias: -23635958208.053440, T: 532, Avg. loss: 172891201836328073079816192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 34330057267.88, NNZs: 1, Bias: -5499248326.473007, T: 570, Avg. loss: 110685602113612212206567424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 117015544128.70, NNZs: 1, Bias: -19456221222.588036, T: 608, Avg. loss: 175711048825601919201312768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 64964062749.87, NNZs: 1, Bias: -12032842182.441704, T: 646, Avg. loss: 170508344995460085262057472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 87229948429.97, NNZs: 1, Bias: 13422824558.312328, T: 684, Avg. loss: 116505697655210799330754560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 64909775584.39, NNZs: 1, Bias: 26969445346.157616, T: 722, Avg. loss: 117114624018243046529302528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 137097587032.02, NNZs: 1, Bias: 28376671875.726257, T: 760, Avg. loss: 133171184069329926179782656.000000\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 20 epochs took 0.01 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 31176805219.87, NNZs: 1, Bias: -12991611465.127913, T: 44, Avg. loss: 574446558545147624480047104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 205515585728.37, NNZs: 1, Bias: -21657363546.547218, T: 88, Avg. loss: 359090368850331310453948416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 226440008560.70, NNZs: 1, Bias: -32844085286.751732, T: 132, Avg. loss: 315330796891491163617361920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 358405452833.76, NNZs: 1, Bias: -33081177521.152103, T: 176, Avg. loss: 154314890481996993092648960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 84192894185.33, NNZs: 1, Bias: -58009582494.478172, T: 220, Avg. loss: 222805792276051341258784768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 116231955024.40, NNZs: 1, Bias: -92401406892.201370, T: 264, Avg. loss: 261780019175009141760458752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 113286470684.55, NNZs: 1, Bias: -74364093257.308197, T: 308, Avg. loss: 234655927940038199684890624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 143592957337.81, NNZs: 1, Bias: -65311874141.948967, T: 352, Avg. loss: 217878118817624720049963008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 284105606425.58, NNZs: 1, Bias: -47413997018.110992, T: 396, Avg. loss: 124651591587370525219880960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 17496847753.59, NNZs: 1, Bias: -40199043557.184013, T: 440, Avg. loss: 146535884020609005035454464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 19239467469.73, NNZs: 1, Bias: -43988133994.366333, T: 484, Avg. loss: 182735950732443511341187072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 328881284883.00, NNZs: 1, Bias: -46868189109.894249, T: 528, Avg. loss: 120973298151864479581732864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 20904590184.60, NNZs: 1, Bias: -48370935253.422745, T: 572, Avg. loss: 99208751710475679675973632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 157881568071.08, NNZs: 1, Bias: -55065899739.705009, T: 616, Avg. loss: 136338199719077097355870208.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 17400103755.33, NNZs: 1, Bias: -48196109259.398766, T: 660, Avg. loss: 112083688096997079794057216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 128009563020.62, NNZs: 1, Bias: -50849270809.668915, T: 704, Avg. loss: 80367638760522247355498496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 84464725968.63, NNZs: 1, Bias: -55259509917.394279, T: 748, Avg. loss: 108865598833236238969864192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 76671536708.24, NNZs: 1, Bias: -46892247219.522675, T: 792, Avg. loss: 103480717327986341393203200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 62504603357.25, NNZs: 1, Bias: -55793067776.023224, T: 836, Avg. loss: 115069607978457604194041856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 73694833771.59, NNZs: 1, Bias: -45625033202.158012, T: 880, Avg. loss: 106381395507072891592114176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 81440387405.68, NNZs: 1, Bias: -48975665461.995087, T: 924, Avg. loss: 116616890314124508113403904.000000\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 21 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 451589288857.51, NNZs: 1, Bias: 1432708169.155450, T: 51, Avg. loss: 532876342235093478867468288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 225730628455.35, NNZs: 1, Bias: 20887977542.619263, T: 102, Avg. loss: 345770249896984594991808512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 45917438658.13, NNZs: 1, Bias: 27795742847.815582, T: 153, Avg. loss: 300585565247956833571700736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 90690732884.11, NNZs: 1, Bias: 24972613228.738647, T: 204, Avg. loss: 307753598515527549112549376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 6788232086.63, NNZs: 1, Bias: 3021176120.391744, T: 255, Avg. loss: 199575175529191138461220864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 369933947960.12, NNZs: 1, Bias: 16705817428.822330, T: 306, Avg. loss: 116348952308832277417164800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 88698366647.59, NNZs: 1, Bias: 662454728.560516, T: 357, Avg. loss: 179250861640564698427424768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 120962945941.72, NNZs: 1, Bias: -6387882531.876184, T: 408, Avg. loss: 216800573160868802310701056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 349820477888.21, NNZs: 1, Bias: 21651094076.114841, T: 459, Avg. loss: 119208110379703916822528000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 12788597420.46, NNZs: 1, Bias: 19617521223.962524, T: 510, Avg. loss: 135352875089521020623650816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 334934079010.69, NNZs: 1, Bias: 24722014979.875103, T: 561, Avg. loss: 155189882482200081934057472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 11 epochs took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 527582059092.57, NNZs: 1, Bias: -19285369629.032803, T: 57, Avg. loss: 680453428898910324951875584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 154777561866.03, NNZs: 1, Bias: -39242803903.136589, T: 114, Avg. loss: 438517271916625347905323008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 131075900462.48, NNZs: 1, Bias: -52130379708.029190, T: 171, Avg. loss: 309602277703244592120332288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 44279421423.12, NNZs: 1, Bias: -61820496245.884964, T: 228, Avg. loss: 308511474134520501643509760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 251948857492.81, NNZs: 1, Bias: -101982486450.891220, T: 285, Avg. loss: 228604416798777138718179328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 15895764531.94, NNZs: 1, Bias: -100965095431.089554, T: 342, Avg. loss: 243487062091377744753459200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 84188032440.42, NNZs: 1, Bias: -83993030180.617615, T: 399, Avg. loss: 206991633681281966386708480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 128818498420.81, NNZs: 1, Bias: -90473056974.735107, T: 456, Avg. loss: 277373118673218721577697280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 76635355909.63, NNZs: 1, Bias: -112884531354.360229, T: 513, Avg. loss: 159711574900624037651677184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 120207829674.57, NNZs: 1, Bias: -108859560541.143097, T: 570, Avg. loss: 156329905331872758748938240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 49428140586.53, NNZs: 1, Bias: -100387630593.766708, T: 627, Avg. loss: 114223940881164006250774528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 402954519669.72, NNZs: 1, Bias: -85804301855.753006, T: 684, Avg. loss: 83315206188040588143624192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 19038278194.13, NNZs: 1, Bias: -58369824813.637657, T: 741, Avg. loss: 170252785106177534296326144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 1544555873.83, NNZs: 1, Bias: -40643174819.463814, T: 798, Avg. loss: 158526016544183749860917248.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 55040921811.37, NNZs: 1, Bias: -49475256931.280075, T: 855, Avg. loss: 120311415245267486378033152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 149221594110.58, NNZs: 1, Bias: -16650559859.931515, T: 912, Avg. loss: 113977882018879244261654528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 220111847415.44, NNZs: 1, Bias: -21067931086.806904, T: 969, Avg. loss: 125389383555151536930684928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 17 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 172175329883.23, NNZs: 1, Bias: 20119669877.594700, T: 64, Avg. loss: 520406556180950693116379136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 120254428507.30, NNZs: 1, Bias: 23015602007.945896, T: 128, Avg. loss: 318716091973888072862400512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 250385766962.37, NNZs: 1, Bias: 24504842695.430237, T: 192, Avg. loss: 208784526645070662117359616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 120389097652.57, NNZs: 1, Bias: 14276211086.772125, T: 256, Avg. loss: 240685715539335878985908224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 132194037564.46, NNZs: 1, Bias: 23467729714.891945, T: 320, Avg. loss: 134239495838041931069259776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 269229420621.40, NNZs: 1, Bias: 24075771839.278404, T: 384, Avg. loss: 173650311513184247193010176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 55012099192.00, NNZs: 1, Bias: -733744823.198416, T: 448, Avg. loss: 254354112906317552810983424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 18199718110.36, NNZs: 1, Bias: 26872976739.161304, T: 512, Avg. loss: 217573631847768878445756416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 42236141940.40, NNZs: 1, Bias: 30982168536.659138, T: 576, Avg. loss: 175418263656670299361902592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 161375034331.14, NNZs: 1, Bias: 18824338397.026215, T: 640, Avg. loss: 175993437070076710706216960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 10 epochs took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "train_sizes, train_scores, test_scores = learning_curve(\n",
    "    estimator= gs.best_estimator_, \n",
    "    X= X_std, \n",
    "    y = Y, \n",
    "    train_sizes=np.arange(0.1,1.1,0.1), \n",
    "    cv= 5, \n",
    "    scoring='r2', \n",
    "    n_jobs= - -1)\n",
    "\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.plot(train_sizes, train_mean, color='blue', marker='o', markersize=5, label='training accuracy')\n",
    "plt.fill_between(train_sizes, train_mean + train_std, train_mean - train_std, alpha=0.15, color='blue')\n",
    "plt.plot(train_sizes, test_mean, color='green', linestyle='--', marker='s', markersize=5, label='validation accuracy')\n",
    "plt.fill_between(train_sizes, test_mean + test_std, test_mean - test_std, alpha=0.15, color='green')\n",
    "plt.grid()\n",
    "plt.xlabel('Number of training samples')\n",
    "plt.legend(loc='lower right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Notes:\n",
    "\n",
    "* For each of the folds, show learning curves (along epochs) of the cost and correlation from the training and test(or validation) data where applicable\n",
    "\n",
    "* Draw plots using matplotlib\n",
    "\n",
    "* Please discuss each of your results with at least few lines of text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
